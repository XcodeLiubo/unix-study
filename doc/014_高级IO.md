### 引言
- 前面所有的IO从调用类型来看, 分为2类:系统调用IO. 也称为文件IO(<font color = green>章节标题</font>), 这种IO不带缓冲;标准IO. 它依赖于系统调用IO, 但标准库在实现时作了用户级别的缓冲(<font color = green>回顾第5章</font>); 操作系统公开的IO接口是统一的, 但实际会根据文件类型的不同, IO的效果也不同. 举例来说: 读取普通文件时(`目录或文本文件`)会立即返回; 读取设备时如标准输入会因为没有数据而阻塞进程. 本章就是更加细分阻塞IO的读取操作. 怎么解决阻塞IO会涉及到更多的技术: 非阻塞IO, 记录锁, IO多路转接, 异步IO, 存储映射IO等. 后面章节还会介绍到网络间的数据IO操作


### 非阻塞IO
- 回顾第10章系统调用分为2类: 低速系统调用和其他. 低速系统调用可能会<font color = deeppink>永久阻塞</font>当前进程, 这一类的系统调用, 包括:
    - 若读取文件数据不存在时, 读操作可能会阻塞调用者. 一般是管道,终端设备,网络设备
    - 若写入文件时, 数据不能被立即接受, 则可能阻塞当前进程.(如管道中没有空间, 网络设备等)
    - 打开某些类型的文件时可能阻塞当前进程. 如打开一个终端设备, 等待接连的调制解调器应答. 又如以写模式打开管道时, 在没有其他进程以读模式打开时也要等待
    - 对已经上写锁的文件进读写时, 也会阻塞当前进程
    - 某些ioctl操作
    - 某些进程间通信
    
> PS: 当进行磁盘读写操作时, 可能会暂时阻塞调用者, 但不能视为低速, 当不可写时, 会立即返回到调用者. 

- 所谓的非阻塞IO表示发起读写操作时不发生永久阻塞的情况, 即使这些对象是设备,管道等. 若不能立即进行则出错返回到用户. 所有的文件都可以在调用<font color = deeppink>open</font>函数时可以指定非阻塞IO的选项(`O_NONBLOCK`). 对于已经打开的文件, 可以通过`fcntl`函数改为非阻塞模式


- `O_NONBLOCK`选项是文件状态标志. 回顾第3章该标志属于文件表项, 它和文件描述符表是分开的. 其`fork`和`dup, dup2`函数会使其共享文件表项. 下面的2个demo是测试非阻塞的2种不同的版本
    1. 标准IO
    2. 文件IO

<br/>

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<sys/stat.h>
#include<fcntl.h>
#include<iostream>
#include<cstdio>

using namespace std;

char buf[64];

int main(int arg, char** argv){
    chdir("/Users/liubo/Desktop/work/study/code");
    // 这里要打开管道, 加上标准IO在调用fopen不能指定文件选项
    // 所以这里发现没有写者时是阻塞的
    file = fopen("./test.pipe", "r");

    if(file == nullptr){
        perror("fopen");
        exit(-1);
    }


    // 代码来这里, 说明已经从管道中读取到了内容
    cout << "open suc\n";

_read:
    if(fgets(buf, sizeof(buf), file)){
        if(ferror(file)){
            // 阻塞模式下只需要判断 EINTR, EAGAIN是非阻塞模式下的假错
            // 非阻塞下对于管道来说, 若写端关闭了, 没有内容时返回的是0, 并不是EAGAIN
            // 只有当写端未关闭, 没有内容可读时, 才会返回EAGAIN
            if(/*errno == EAGAIN ||*/ errno == EINTR)
                goto _read;
            exit(-1);
        }

        if(feof(file)){
            // 结束后, 立即往下执行测试非阻塞模式
        }
    }

    cout << "read suc:" << buf << endl;
    clearerr(file);


    // 获取当前的文件状态标志
    auto file_fd = fileno(file);
    auto o_file_status = fcntl(file_fd, F_GETFL);
    // 判断当前文件状态标志是不是非阻塞的, 若是则直接阻塞
    if(o_file_status & O_NONBLOCK){
        fcntl(file_fd, F_SETFL, o_file_status & (~O_NONBLOCK));
    }else{
        fcntl(file_fd, F_SETFL, o_file_status | O_NONBLOCK);
    }

    while(1){
        // 没有数据时, if返回为空, 会在这里不断循环读取管道
        if(ferror(file)){
            if(errno == EAGAIN){
                cerr << "over\n";
                clearerr(file);
                continue;
            }
            exit(-1);
        }
        if(feof(file)){
            cerr << "eof\n";
            clearerr(file);
            continue;
        }
        if(fgets(reinterpret_cast<char*>(buf), sizeof(buf), file)){
            cout << "read suc:" << buf << endl;
            clearerr(file);
        }
    }
    fclose(file);
    return 0;
}
```

<br/>

> 上述使用的是标准IO, 这里要注意:标准IO在发起`fgets`后, 会一次性读取一大块文件数据到缓冲内存中, 然后再一个一个从存在中读取. 这里在出现`EINTR`时是一种假错(`回顾第10章`), 有的系统调用会自动重启(`也是第10章`), 当调用发生阻塞时, 可能会被其他信号中断, 但不应该视为出错. 非阻塞模式时, 不要管这个信号 


<br/>

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<sys/stat.h>
#include<fcntl.h>
#include<iostream>
#include<cstdio>

using namespace std;

int8_t buf[64];

int main(int arg, char** argv){
    chdir("/Users/liubo/Desktop/work/study/code");
    // 以只读打开, 因为内部调用系统调用, 所以默认是阻塞的
    auto fd   = open("./test.pipe", O_RDONLY);
    if(fd < 0){
        perror("open");
        exit(-1);
    }
    cerr << "open suc" << endl;

_read:
    auto res = read(fd, buf, sizeof(buf));
    if(res < 0){
        if(errno == EINTR)
            goto _read;
        exit(-1);
    }

    // 这里表示读取结束, 对于系统IO来说,不用管, 立即进入下面的非阻塞模式的测试
    //if(res == 0){ goto _read;}



    cout << "read suc:" << buf << endl;
    memset(buf, 0, sizeof(buf));

    auto o_file_status = fcntl(fd, F_GETFL);
    // 判断当前文件状态标志是不是非阻塞的, 若是则直接阻塞
    if(o_file_status & O_NONBLOCK){
        cout << "原来是非阻塞的\n";
        fcntl(fd, F_SETFL, o_file_status & (~O_NONBLOCK));
    }else{
        cout << "原来是阻塞的\n";
        fcntl(fd, F_SETFL, o_file_status | O_NONBLOCK);
    }

    while(1){
        res = read(fd, buf, sizeof(buf));
        if(res < 0){
            if(errno == EAGAIN){
                continue;
            }
            exit(-1);
        }
        if(res == 0){
            continue;
            break;
        }
        cout << "read suc:" << buf << endl;
        memset(buf, 0, sizeof(buf));
    }

    close(fd);
    return 0;
}
```

<br/>

> 上述是系统IO, 编写和标准IO一样. 但它们的运行机制不一样, 系统IO每次只读要求长度的数据. 这里要再说明一下: 系统IO在读取操作时内部有自己的优化机制, 它也会向磁盘索取一大块数据放入到内存中. 原理和标准IO一样. 但2者在速度上有很大不同, 标准IO要快的多. 因为系统IO是将数据存放到内核缓冲区, 每次系统IO的操作, 会发生一次内核缓冲区到用户缓冲区的复制. 而标准IO一般读取的长度会比要求的多, 它调用系统IO一次性索取更大的数据, 直接从内核缓冲区复制到用户缓冲区后, 再在用户缓冲区处理. 向内核调用的次数越少, 用户态及内核态2者之间的转换就越少, 复制操作就越少, 速度就越快. 其实这种速度的差异主要体现在数据量少的情况.
>
> 实际上标准IO不能在打开文件时就指定非阻塞模式, 本例能测试成功是因为启动后就要测试阻塞模式. 如果要求使用标准IO来处理, 则流程上应该先创建文件描述符, 即调用系统IO在打开时就指定非阻塞模式, 再将文件描述符转换成FILE
>
> 以上程序不适合用c++的文件流处理: 
>   1. 这里要求非阻塞IO, 但在c++的流对象中无法获取到FILE对象, 所以无法找到文件描述符来进行设置(`某些非标准可以`).
>   2. 文件流在构造时就直接读取文件, 由于打开文件时默认是阻塞式的, 以本例中的管道来说构造时就阻塞了
>   3. 文件流读取管道时, 无法判断当前文件是否结束. 
>   4. 若文件写者关闭, 则文件流读取时出错, 其实和第3条一样
>

<br/>


### clang,g++获取文件描述符

- 笔者当前的clang版本为`15.0.0`, 架构为`M2(Arm64)`. 这个版本的标准库有2种方式可以得到FILE对象: 第1种是验证源码所整理出来的结构, 在代码中经过类型的强制转换可以取到FILE对象; 第2种也是观察了结构, 但是通过继承重写方式, 这种方法可以先创建文件描述符.

```cpp

#if defined(__APPLE__) && __clang_major__ == 15 && __clang_minor__ == 0 && __clang_patchlevel == 0

// 第1种方法 
struct my_buf{
    void* ptr;
    void* _1;
    void* __binp_;
    void* __ninp_;
    void* __einp_;
    void* __bout_;
    void* __nout_;
    void* __eout_;

    char* __extbuf_;
    const char* __extbufnext_;
    const char* __extbufend_;
    char __extbuf_min_[8];
    size_t __ebs_;
    void* __intbuf_;
    size_t __ibs_;
    FILE* __file_;      // 整理到FILE就可以了, 后面的不用管

    //...
};

int main(int arg, char** argv){
    ifstream inf("./test.pipe", std::ios::ios_base::in);

    // rdbuf成员函数是标准公开可调用的, 获取到的ptr类型是文件流中的缓冲对象指针
    // 该对象是私有的, 但整理出来的结构可简化成上述的 my_buf
    auto ptr = inf.rdbuf();
    my_buf* tmp_ptr = reinterpret_cast<my_buf*>(ptr);
    FILE* file = tmp_ptr->__file_;

    // 获取当前的文件状态标志
    auto file_fd = fileno(file);
    auto o_file_status = fcntl(file_fd, F_GETFL);
    // 判断当前文件状态标志是不是非阻塞的, 若是则直接阻塞
    if(o_file_status & O_NONBLOCK){
        fcntl(file_fd, F_SETFL, o_file_status & (~O_NONBLOCK));
    }else{
        fcntl(file_fd, F_SETFL, o_file_status | O_NONBLOCK);
    }
    return 0;
}









// 第2种方法
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<iostream>
#include<fstream>
#include<string>
#include<cerrno>
#include<cstdio>

using namespace std;

// 对于 ofstream和 fstream也是同样的道理
class MyIFile : public ifstream{
public:
    // 添加一个public对外的方法, 然后内部调用 set_rdbuf, 这个方法是protected, 所以才建了一个子类
    void set_mybuf(basic_filebuf<char_type, traits_type>* b){
        this->set_rdbuf(b);
    }
};

int main(){
    auto fd = open("./a.pipe",  O_RDONLY | O_NONBLOCK);
    if(fd < 0){
        perror("open");
        exit(-1);
    }

    // basic_filebuf这个类以及 basic_filebuf.__open方法 是公开的
    // 该方法可以以文件描述符打开
    basic_filebuf<MyIFile::char_type, MyIFile::traits_type> b;
    b.__open(fd, ios_base::in);



    // 用自定义的文件类
    MyIFile m;
    m.set_mybuf(&b);        // 内部会调用到父类


    // 测试程序
    string s;
    m >> s;
    cout << s;

    return 0;
}
#endif
```

<br/>

- 对应的在g++环境`9.4.0, Arm64`版本

```cpp
#if defined(__GNUC__) && __GNUC__ == 9 && __GNUC_MINOR__ == 4 &&  __GNUC_PATCHLEVEL__ == 0
template<typename char_type, typename T>
class my_filebuf{
public:
      void*             vptr;
      void* 		_M_in_beg;     ///< Start of get area.
      void* 		_M_in_cur;     ///< Current read area.
      void* 		_M_in_end;     ///< End of get area.
      void* 		_M_out_beg;    ///< Start of put area.
      void* 		_M_out_cur;    ///< Current put area.
      void* 		_M_out_end;    ///< End of put area.
      std::locale       _locale;
      __gthread_mutex_t _1;		//
      FILE*		file;		//
};

int main(int args, char** argv){
	using namespace std;
	using MyBuf =  my_filebuf<ifstream::char_type, ifstream::traits_type>;
	ifstream f("./a.txt", ios_base::in);
	MyBuf* buf = (MyBuf*)(f.rdbuf());
	auto fd = fileno(buf->file);
	return 0;
}
#endif
```

<br/>

> g++这种只能获取到FILE, 换言之只能是通过流打开文件后, 才能获取到, 不能在打开文件前通过fd产生流. 开发中不要使用c++的流来处理非阻塞的IO

<br/>




### 轮询
- 非阻塞IO看起来好像对开发没什么用, 它读取低速设备时, 在失败后可以尝试再进行读取(`如果业务要求必须读取到数据`), 这样会因为读不到数据一直占据CPU, 导致资源浪费, 还不如阻塞等待数据返回. 但若需求是同时读取多个低速设备, 那以现在的知识来实现, 必须用到非阻塞IO. 因为若用阻塞IO的话, 会导致在等待其中一个IO设备时, 不能知道其他设备有没有数据到来, 所以只能遍历时时检查每个设备是否有数据, 有的话就读. 
    > 当然可以使用多线程技术, 对于每1个低速设备者使用阻塞IO, 但现在这里不讨论这个

```txt
4个管道
    a.pipe
    b.pipe
    c.pipe
    d.pipe
    
    PS: mkfifo 创建管道的命令


2个进程
    1. 读进程
    2. 写进程
    
    2个进程都只用1条线程
    打开4个管道. 
    进程1开启非阻塞模式读取, 并且时时循环检查是否有数据. 
    进程2是写模式, 它每隔1秒循环4次, 向4个管道中写入数据

    PS: 因为当前测试案例使用的是 makefifo创建的命名管道文件.
        在只写打开时指定非阻塞会因为没有读者就直接结束. 
        所以在代码中使用pipe创建一个匿名管道可以进行非阻塞写
```

<br/>

> 写入端代码

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<iostream>
#include<thread>
#include<cerrno>
#include<cstdio>
#include<cstdlib>
#include<algorithm>

using namespace std;

static constexpr const char* PATH[] = {
    "./a.pipe",
    "./b.pipe",
    "./c.pipe",
    "./d.pipe",
};

static constexpr auto LEN = 4;

static FILE* FILES[LEN] = {nullptr};

static constexpr auto BUF_SIZE = 64;
static int8_t BUF[LEN][BUF_SIZE] = {0};

int main(int args, char** argv){
    chdir("/Users/liubo/Desktop/work/study/code");

    // 因为是写入, 直接通过 fopen打开文件
    for(int i = -1, j = LEN; ++i < j;){
        FILES[i] = fopen(PATH[i], "w");
        if(FILES[i] == nullptr){
            perror("fdopen");
            exit(-1);
        }
    }

    // 每隔1秒向4个管道写入数据
    while(1){
        for(int i = -1; ++i < LEN;){
            snprintf(reinterpret_cast<char*>(BUF[i]), BUF_SIZE, "%d--hello\n", i);
            if(fputs(reinterpret_cast<char*>(BUF[i]), FILES[i])){
                fflush(FILES[i]);
            }

            // 这里直接通过 fputs的返回值来判断是否写入成功
            // 比较严谨的作法是调用 feof 和 ferror来检测流的状态
        }
        sleep(1);
    }


    // 等待线程结束
    for_each(begin(FILES), end(FILES), [](FILE* file){
        fclose(file);
    });   

    return 0;
}
```

<br/>

> 读取端代码

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<iostream>
#include<thread>
#include<cerrno>
#include<cstdio>
#include<cstdlib>
#include <algorithm>

using namespace std;

static constexpr const char* PATH[] = {
    "./a.pipe",
    "./b.pipe",
    "./c.pipe",
    "./d.pipe",
};

static constexpr auto LEN = 4;

static FILE* FILES[LEN] = {nullptr};

static constexpr auto BUF_SIZE = 64;
static int8_t BUF[LEN][BUF_SIZE] = {0};

int main(int args, char** argv){
    chdir("/Users/liubo/Desktop/work/study/code");

    // 读取端设置非阻塞, 必须通过文件描述符, 然后再映射到FILE
    for(int i = -1, j = LEN; ++i < j;){
        auto file_fd = open(PATH[i], O_NONBLOCK | O_RDONLY);
        if(file_fd < 0){
            perror("open");
            exit(-1);
        }
        FILES[i] = fdopen(file_fd, "r");
        if(FILES[i] == nullptr){
            perror("fdopen");
            exit(-1);
        }
    }

    cout << "open suc\n";

    // 这里将消耗大量的CPU资源
    while(1){
        for(int i = -1, j = LEN; ++i < j;){
            auto res = fgets(reinterpret_cast<char*>(BUF[i]), BUF_SIZE, FILES[i]);
            if(ferror(FILES[i])){
                if(errno == EAGAIN){
                    clearerr(FILES[i]);
                    continue;
                }
                perror("fgets");
                exit(-1);
            }

            if(feof(FILES[i])){
                clearerr(FILES[i]);
                continue;
            }
            if(res){
                cout << reinterpret_cast<const char*>(BUF[i]) << endl;
                clearerr(FILES[i]);
            }
        }
    }

    for_each(begin(FILES), end(FILES), [](FILE* file){
        fclose(file);
    });

    return 0;
}
```

<br/>

> 测试结果如下面的这张gif图, main表示写入进程, main2表示读取进程

---

<img src="./assets/14_01.gif" />

---

<br/>

> 上述通过循环遍历来时时查看管道非常消耗资源. 对于该程序的测试模式绝大部分出错的情况是`EAGAIN`.  在这些案例中, write的操作都是阻塞式的, 但其实它本身也可以是非阻塞式, 以管道为例, 当管道中的数据满了后, 若是非阻塞则会出现`EAGAIN`. 下面的demo可以验证这一点

<br/>

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<iostream>
#include<thread>
#include<cerrno>
#include<cstdio>

using namespace std;

int main(int args, char** argv){
    char buf[20] = {0};

    int fds[2] = {};

    if(pipe(fds) < 0){          // __code_creat_pipe
        perror("pipe");
        exit(-1);
    }

    // fds[0]是读  fds[1]是写

    // 同时设置读写端为非阻塞
    fcntl(*(fds+1), F_SETFL, fcntl(*(fds + 1), F_GETFL) | O_NONBLOCK);
    fcntl(*(fds), F_SETFL, fcntl(*(fds), F_GETFL) | O_NONBLOCK);

    
    int res = 0;
    auto count = 0ull;
    do{
        snprintf(buf, 20, "hello wrld\n");
        res = write(*(fds+1), buf, 20);
        if(res < 0){
            // 管道满了会出现这种情况, 应该继续写
            if(errno == EAGAIN){
                cerr <<  "管道满了, 字节数:" << count << endl;
                break;
            }
            perror("write");
            exit(-1);
        }
        // end 
        if(res == 0){
            continue;
        }
        count += (strnlen(buf, 20));
        memset(buf, 0, 20);
    }while(res);


    while(pause());
    close(*fds);
    close(*(fds + 1));
    return 0;
}
```

<br/>

> 上述程序创建了一个匿名管道(`__code_creat_pipe`). 并且同时设置读写2端为非阻塞模式. 为了测试, 并未去读取管道, 当程序运行后, 只有写入的一端, 当前管道满了后, 因为是非阻塞的, 所以产生了`EAGAIN`信号, 直接结束. 测试结果如下

<br/>

```shell
./main
管道满了, 字节数:36036
^C
```



<br/>

### 逐渐引申到IO多路转接
- 思来想去笔者准备通过实际场景来从轮询过渡到IO多路转接. 这样不仅对其概念会加深理解, 也会就相关问题给出解决方案.

```txt
场景:
    模拟socket的2端通信. 

分析:
    因为现在还未学习到socket, 所以demo中将使用管道来实现. 但面临的问题是:
        1. shell创建的管道在以只写时指定非阻塞会因为没有读者而直接结束, 所以最
            开始的程序都使用的是匿名管道

        2. 标准规定管道是单向的, 不允许在一个端进行读写.

        3. 通信时双方要读对方的内容, 并且还要反馈给对方内容

        4. 单方处理2条管道, 怎么实现不阻塞监听管道的内容以达到及时响应

解决
    问题1
        代码中使用匿名管道(也可以使用命名管道). 因为这种形式创建的管道可以非阻塞的读写

    问题2, 3:
        使用2条匿名管道. 
        假设
            2个进程
                A, B 
            2条管道
                P1, P2

        规定: 
            A读P1, 写P2
            B读P2, 写P1


下面的图展示了这个流程
```

<br/>

```mermaid
flowchart LR
    A ---->|a wto P2 == b rfr P2| B
    B ---->|a rfr P1 == b wto P1| A
```

<br/>

> `wto`表示`write to`. `rfr`表示`read from`

<br/>

```txt
    上图其实隐含了一个新的问题:
        以A来说, (A write to P2) 的操作必须由 (A read from P1) 的操作成功, 即读取到了数据.
        换句话说就是写的动作是由读的动作驱动的. 对于B来说也是一样的, B只有读取到了数据(B read from P2),
        才会 (B write to P1).

    解决:
        以A来说, 轮询(A read from P1)
            > 成功后(A write to P2)
            > 失败关闭退出

        以B来说, 轮询(B read from P2)
            > 成功后 B write to P1
            > 失败关闭退出
```

<br/>

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<iostream>
#include <thread>
#include<tuple>
#include<cerrno>
#include<cstdio>

using namespace std;


/** 指示poll时的动作*/
enum class OPER_STA {
    read,
    write,
    over,       // 正常结束
    ex          // 异常结束
};

struct pipe_descripe{
    int rfd;
    int wfd;
};
static pipe_descripe PIPES[2];

auto constexpr BUF_SIZE = 128;
static int8_t BUF[BUF_SIZE];

// 规定第0组是P1, 第1组是P2
static inline pipe_descripe* get_pipe(bool child = false){
    return child ? (PIPES + 1) : PIPES;
}

#define P1() get_pipe()
#define P2() get_pipe(true)

#define PR (P1()->rfd)      // parent == A ==> A read from P1
#define PW (P2()->wfd)      // parent == A ==> A write to P2
#define CR (P2()->rfd)      // child  == B ==> B read from P2
#define CW (P1()->wfd)      // child  == B ==> B write to P1

// 创建2个管道
static void make_pipe(pipe_descripe* const pipe_arr){
    if(pipe(reinterpret_cast<int*>(get_pipe())) < 0){
        perror("pipe");
        exit(-1);
    }

    if(pipe(reinterpret_cast<int*>(get_pipe(true))) < 0){
        perror("pipe");
        exit(-1);
    }

    // 4个文件描述符设置为非阻塞的
    fcntl(PR, F_SETFL, fcntl(PR, F_GETFL) | O_NONBLOCK);
    fcntl(PW, F_SETFL, fcntl(PW, F_GETFL) | O_NONBLOCK);
    fcntl(CR, F_SETFL, fcntl(CR, F_GETFL) | O_NONBLOCK);
    fcntl(CW, F_SETFL, fcntl(CW, F_GETFL) | O_NONBLOCK);

    // PS: 注意实际开发中, 该函数应该是一个模块, 在开始前设置文件描述符, 结束后为还原,
    //     这里偷懒没有还原
}



static void poll(bool child = false){
    tuple<int,int> fds;
    get<0>(fds) = child?CR : PR;
    get<1>(fds) = child?CW : PW;

    // get<0> 表示 read
    // get<1> 表示 write

    // 必须有一方先发起通信(因为没有服务器器来中转), 这里选择父进程
    OPER_STA state = child ? OPER_STA::read : OPER_STA::write;
    while(1){
        switch(state){
            case OPER_STA::read:{
                auto rn = read(get<0>(fds), BUF, BUF_SIZE);
                if(rn < 0){
                    if(errno == EAGAIN){ // 只是退出swich, 还是会循环来这里
                       // sleep(1);
                        break;
                    }
                    state = OPER_STA::ex;
                }
                
                if(rn == 0){
                    //管道有结束状态, 要继续读取
                    //state = OPER_STA::over;
                    break;
                }
                state = OPER_STA::write;
            }break;

            case OPER_STA::write:{
                if(strlen(reinterpret_cast<char*>(BUF))){
                    // 这里是模拟, 先将收到的信息回显到屏幕, 然后从标准输入键入消息, 发送出去
                    cout << (child ? "child" : "parent") << " receive:" << BUF << "\nreplay:" << flush;
                }else{
                    cout << "send msg to " << (child ? "parent" : "child") << ":" << flush;
                }
                memset(BUF, 0, BUF_SIZE);
                string msg;
                getline(cin, msg);

                ssize_t pos = 0;
                string::size_type wn = 0;
                while(1){
                    wn = write(get<1>(fds), msg.c_str() + pos, msg.length());
                    if(wn < 0){
                        if(errno == EAGAIN)
                            continue;

                        // 出错, 结束
                        state = OPER_STA::ex;
                        break;
                    }

                    // 记录这一次写入的数据量
                    pos += wn;  

                    // 表示回复的内容已经全部写完, 继续监听read
                    if(pos == msg.length()){
                        pos = 0;
                        state = OPER_STA::read;
                        break;
                    }
                }
            }break;

            case OPER_STA::over:{
                cout << "over\n" << flush;
                exit(0);
            }break;

            case OPER_STA::ex:{
                child?perror("child err"):perror("parent err");
                exit(-1);
            }break;

            default:
                cerr << "no oper type\n";
                exit(-1);
                break;
        }
    }
}


int main(int args, char** argv){

    make_pipe(PIPES);

    auto child = fork();
    if(child < 0){ perror("fork"); exit(-1);}


#if 0
    fork前有2个管道
    PIPES[0] 表示P1
    PIPES[1] 表示P2

    fork后就有了4个管道
    子进程也是一模一样的.
    但开发中, 一般会在父子进程中关闭相关的描述符
#endif

    if(!child){ // chhild中
        // 子进程关闭 P1的读, 因为它只写P1
        close(P1()->rfd);
        // 子进程关闭 P2的写, 因为它只读P2
        close(P2()->wfd);

        poll(true);

        return 0;
    }

    // 父进程关闭 P1的写, 因为它只从P1读
    close(P1()->wfd);
    // 父进程关闭 P2的读, 因为它只写P2
    close(P2()->rfd);

    poll();

    return 0;
}
```

<br/>

> 上述程序很简单, 模拟实现2方对话. 因为父子进程应该由read操作来驱动write, 所以开始后必须有1方先发送个消息. 当有1方收到消息后, 另一方会从read状态取到消息, 然后回显到屏幕, 之后从键盘输入回复的内容, 以此模式来进行通信. 下面是测试结果:

---

<img src="./assets/14_02.gif"/>

---

<br/>

> 该版本存在问题: 虽然在逻辑上区分开了用户A和B(`程序中使用了父子进程`), 但不符合应用场景. 实际应该是不同的2端通过中间方来间接通信. 中间方类似于一个服务进程. 如下图


```mermaid
flowchart LR
    A ---->|a wto PSA =>= s rfr PSA | S ---->|s wto P2 =>= b rfr P2| B
    B ---->|s rfr PSB =<= b wto PSB| S ---->|a rfr P1 =<= s wto P1| A
```

<br/>

> 图中的`S`表示`service`. A和B的通信必须由S来中转. 所以多了2条管道PSA和PSB. 
>
> 大致逻辑是: S通过 PSX 管道接收来自A和B的消息, 同时通过 PX 管道又将消息转发给对方. 图中涉及到了多条管道, 看起来比较复杂冗余, 原因是管道的机制是单工的[^ann-pipe-0], 单纯的2方通信时, 用2条管道在逻辑上会更清晰.
>
> 下面的代码使用了命名管道, 并在逻辑架构上将角色区分开了. 有所谓的S端(服务器)和用户端(U). 首先看一下架构 

<br/>

```txt
    S端:
        1. 启动就打开 sa.pipe和sb.pipe, 扫描连接(connect --> read)
        2. 提取消息(read的回调)类型:
            > login:对方请求登录, 然后打开px管道, 回复对方登录成功
            > quit: 退出, 这里是服务器直接结束
            > r: 表示消息转发, 切换管道(从回复登录成功切换到转发对方用户), 同时消息写入转发管道

    U端:
        1. 启动打开 px.pipe, sx.pipe
        2. 子线程中从标准输入中获取内容写入到 sx.pipe
            > 同时将内容记录到文件 xx.db
        3. 主线程扫描px.pipe
            > login success: 登录成功的回调, 将其写入文件, 再进入到read
            > 其他消息, 写入到文件


    类:
        service
        
        user

        msg(辅助类)
            统一了状态, 对于S来说可能用到较多的状态, 对于user来说, 可能只用到了 read, login等少数的状态
```

<br/>

> 结构树

```shell
├── server.cpp
├── msg.cpp
├── msg.h
└── msg_protocol.h


├── main
├── main.cpp
├── msg.cpp
├── msg.h
└── msg_protocol.h


## 管道文件 sa.pipe sb.pipe p1.pipe p2.pipe
```

<br/>


```cpp
// 资源头文件msg_protocol.h
#ifndef __MSG_PROTOCOL_H__
#define __MSG_PROTOCOL_H__

constexpr auto CONNECT_PIPE_SA  = "./sa.pipe";    // s read from sa <==> a write to sa
constexpr auto CONNECT_PIPE_SB  = "./sb.pipe";    // s read from sb <==> b write to sb
constexpr auto CONNECT_PIPE_P1  = "./p1.pipe";    // s write to P1  <==> a read from P1
constexpr auto CONNECT_PIPE_P2  = "./p2.pipe";    // s write to P2  <==> b read from P2


#ifdef SERVER       // server进程使用
#include <map>
#include <tuple>
#include <cstdio>
static inline std::map<decltype(CONNECT_PIPE_P1), std::tuple<FILE*, int>>& _init(void){
    static std::remove_const_t<std::remove_reference_t<decltype(_init())>> rmap;
    return rmap;
}

#define MAP (_init())
#define SA (std::get<0>(MAP[CONNECT_PIPE_SA]))
#define SB (std::get<0>(MAP[CONNECT_PIPE_SB]))
#define P1 (std::get<0>(MAP[CONNECT_PIPE_P1]))
#define P2 (std::get<0>(MAP[CONNECT_PIPE_P2]))
#endif


#endif /* __MSG_PROTOCOL_H__ */





// msg.h
#ifndef __MSG_H__
#define __MSG_H__

#include <cstdio>

#define NAME_SPACE_BEGIN(_name)  namespace _name {
#define NAME_SPACE_END(_name)    }


#define MSG_ALIGN \
    __attribute__((aligned(sizeof(void*))))


NAME_SPACE_BEGIN(lbmsg)


enum class iostatus{
    CONNECT,
    LOGIN,
    READ,
    WRITE,
    QUIT,
    EXCEPTION,
    TERM,
}MSG_ALIGN;

struct msg{
    static constexpr auto BUF_LEN          = 0x100;
    iostatus    status;
    FILE*       sfile;
    FILE*       dfile;
    union{
        char        content[BUF_LEN];
        char        err[];
    };

    // 服务器会调用该函数
    void connect(void (*)(lbmsg::msg&));

    // 注意后面的 回调(必须由调用方实现)
    void login(const char* = nullptr, void fun(lbmsg::msg&) = [](lbmsg::msg&self)->void{}) noexcept(false);
    void read(void (*)(lbmsg::msg& self, const char*));
    void write();

    static void write(msg& self, FILE*);

    void quit(void);
    void exception(void);
    void term(void);

    msg& self() const{return const_cast<msg&>(*this);}

}MSG_ALIGN;


NAME_SPACE_END(lbmsg)



#undef MSG_ALIGN

#endif /* __MSG_H__ */



//  msg.cpp
//  unix
//
//  Created by lb on 2024/3/10.
//

#include "msg.h"

#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <iostream>



#define self self()


#ifdef DEBUG
    #define SLEEP(_n) sleep(_n)
#else
    #define SLEEP(_n)
#endif


void lbmsg::msg::quit(void){
    std::cerr << "quit\n";
    this->status = iostatus::TERM;
}

void lbmsg::msg::exception(void){
    perror(this->err);
    this->status = iostatus::TERM;
}

void lbmsg::msg::term(void){
    exit(-1);
}


void lbmsg::msg::connect(void (*fun)(lbmsg::msg&)){
    fun(self);
}

void lbmsg::msg::login(const char* relpay, void (*fun)(lbmsg::msg&)) noexcept(false){
    if(!fun)
        throw "must have a callback";
    if(relpay){
        snprintf(self.content, strlen(relpay) + 1, "%s", relpay);
    }
    fun(self);
}

void lbmsg::msg::read(void (*fun)(msg&, const char*)){
    void* res = nullptr;
    res = fgets(self.content, BUF_LEN, self.sfile);
    if(res)
        return fun(self, self.content);

    if(ferror(self.sfile)){
        if(EAGAIN == errno){
            SLEEP(1);
            clearerr(self.sfile);
            return;
        }
        memcpy(self.err, "read\0", 5);
        self.status = iostatus::EXCEPTION;
        return;
    }

    if(feof(self.sfile)){
        SLEEP(1);
        clearerr(self.sfile);
        return;
    }
}

void lbmsg::msg::write(){
    self.write(self, self.dfile);
}


void lbmsg::msg::write(msg& call, FILE * file){
    int len = static_cast<int>(strnlen(call.content, BUF_LEN));
    int pos = 0;
    int wn = 0;
    while(1){
        wn = fputs(call.content + pos, file);
        if(wn){
            pos += wn;
            if(pos == len){
                memset(call.content, 0, BUF_LEN);
                fflush(file);
                call.status = iostatus::READ;   // 内容发送完毕, 继续读
                break;
            }
            continue;
        }
        if(ferror(call.dfile)){
            if(EAGAIN == errno){
                SLEEP(1);
                clearerr(call.dfile);
                continue;;
            }
            memcpy(call.err, "write\0", 6);
            call.status = iostatus::EXCEPTION;
            break;
        }
    }
}







// U端
#include<unistd.h>
#include<fcntl.h>

#include<iostream>
#include <fstream>
#include<string>
#include<functional>
#include<thread>

#include<cstdio>

#include"msg_protocol.h"
#include"msg.h"

static std::ofstream dbfile;

int main(int args, char** argv){
    if(args != 2){
        std::cerr << "usage ./main <user-type>(user_a or user_b)\n";
        exit(-1);
    }

    std::cout << "tid:" << getpid() << std::endl;
    chdir("/Users/liubo/Desktop/work/study/code");

    std::string cmd_user(argv[1]);
    std::transform(cmd_user.begin(), cmd_user.end(),cmd_user.begin(), ::toupper);
    bool is_a = cmd_user.compare("USER_A") == 0; 

    // 当前用户读PX
    auto rfd = open(is_a ? CONNECT_PIPE_P1 : CONNECT_PIPE_P2, O_RDONLY | O_NONBLOCK);
    if(rfd < 0){
        perror("open");
        exit(-1);
    }
    auto rf = fdopen(rfd, "r");
    if(nullptr == rf){
        perror("fdopen r");
        exit(-1);
    }

    // 当前用户写 SX
    auto wfd = open(is_a ? CONNECT_PIPE_SA : CONNECT_PIPE_SB, O_WRONLY | O_NONBLOCK);
    // 服务器没有打开 SX 管道(以非阻塞写打开管道时, 若没有读端, 会报错)
    if(wfd < 0){
        perror("open");
        exit(-1);
    }
    

    auto wf = fdopen(wfd, "w");
    if(!wf){
        perror("fdopen w");
        exit(-1);
    }


    // 负责将读取到的数据 和 将发送给对方的数据 写入到文件
    dbfile.open(is_a ? "a.db" : "b.db", std::ios::ios_base::out | std::ios::ios_base::trunc);
    if(!dbfile){
        perror("open db fail");
        exit(-1);
    }


    lbmsg::msg sock{
        .status = lbmsg::iostatus::READ,
        .sfile = rf,
        .dfile = wf,
        .content = {0}
    };


    std::thread([](const lbmsg::msg* Self){
        auto& self = *Self;
        char buf[lbmsg::msg::BUF_LEN] = {0};
        while(1){
            std::cin.getline(buf, sizeof(buf));
            dbfile << buf << std::endl;
            fputs(buf, self.dfile);
            fflush(self.dfile);
            memset(buf, 0, sizeof(buf));
        }
    }, &sock).detach();


    while(1){
        switch (sock.status){

            case lbmsg::iostatus::CONNECT:
            case lbmsg::iostatus::WRITE:
            break;

            case lbmsg::iostatus::LOGIN:{
                dbfile << "login success\n" << std::flush;
                sock.status = lbmsg::iostatus::READ;
            }break;

            case lbmsg::iostatus::READ:{
                sock.read([](lbmsg::msg& self, const char* content){
                    std::string str(content);
                    std::transform(str.begin(), str.end(), str.begin(), ::toupper);
                    if(str == "LOGIN SUC"){
                        self.status = lbmsg::iostatus::LOGIN;        // 服务器告诉当前用户登录成功了, 先调整到login, 打印一下日志
                        return;
                    }
                    dbfile << self.content << std::endl;
                });
            }break;

            case lbmsg::iostatus::QUIT:{
                sock.quit();
            }break;

            case lbmsg::iostatus::EXCEPTION:{
                sock.exception();
            }break;

            case lbmsg::iostatus::TERM:{
                sock.term();
            }break;

            default:
                std::cerr << "unrecognized status\n";
                exit(-1);
                break;
        };
    }
    return 0;
}







// S端
#include<unistd.h>
#include<fcntl.h>
#include<iostream>
#include<string>
#include<vector>
#include <functional>
#include <algorithm>

#define SERVER
#include "./msg_protocol.h"
#include "./msg.h"



static void init(void){
    // 最开始只打开 SA 和 SB(P1和P2在客户连上后再打开)
    for(auto& item : {CONNECT_PIPE_SA, CONNECT_PIPE_SB}){
        // 打开文件时以非阻塞打开, 不然会阻塞(后面要映射到file)
        auto connect_fd = open(item, O_RDONLY | O_NONBLOCK);
        if(connect_fd < 0){
            perror("open");
            exit(-1);
        }

        auto file = fdopen(connect_fd, "r");
        if(nullptr == file){
            perror("fdopen");
            exit(-1);
        }
        MAP[item] = std::make_tuple(file, connect_fd);
    }
}

static inline void connect_cbk(lbmsg::msg& self);
static inline void login_cbk(lbmsg::msg& self);
static void read_cbk(lbmsg::msg& self, const char* content);






static void poll(void){
    std::vector<lbmsg::msg> socks{
        {lbmsg::iostatus::CONNECT, SA, nullptr, ""},
        {lbmsg::iostatus::CONNECT, SB, nullptr, ""},
    };
    // 所有的操作当状态改变后, 要等待到下一次循环时才会执行
_begin:
    for(auto& sock : socks){
        switch (sock.status) {
                // 等待连接的状态, 要读取 sfile
            case lbmsg::iostatus::CONNECT:{
                sock.connect(connect_cbk);
            }break;

            case lbmsg::iostatus::LOGIN:{
                sock.login("login suc", login_cbk);
            }break;

            case lbmsg::iostatus::READ:{
                sock.read(read_cbk);
            }break;

            case lbmsg::iostatus::WRITE:{
                sock.write();
            }break;

            case lbmsg::iostatus::QUIT:{
                sock.quit();
            }break;

            case lbmsg::iostatus::EXCEPTION:{
                sock.exception();
            }break;

            case lbmsg::iostatus::TERM:{
                sock.term();
            }break;

            default:
                std::cerr << "unrecognized status\n";
                exit(-1);
                break;
        }
    }
goto _begin;

}





int main(int args, char** argv){
    std::cout << "tid:" << getpid() << std::endl;
    chdir("/Users/liubo/Desktop/work/study/code");

    init();

    poll();

    fclose(SA);
    fclose(SB);
    fclose(P1);
    fclose(P2);
}



static inline void connect_cbk(lbmsg::msg& self){
    self.status = lbmsg::iostatus::READ;
}

static inline void login_cbk(lbmsg::msg& self){
    // 服务器回复 发送方 登录成功(注意不能将消息发送到 另一方客户)
//    lbmsg::msg::write(self, self.sfile == SA ? P1 : P2);
    self.status = lbmsg::iostatus::WRITE;
}

static std::tuple<FILE*, int> open_pipe(lbmsg::msg& self,decltype(CONNECT_PIPE_P1) pipe, int mode = O_NONBLOCK | O_WRONLY){
    auto fd = open(pipe, mode);
    if(fd < 0){
        memcpy(self.err, "open\0", 5);
        self.status = lbmsg::iostatus::EXCEPTION;
        return std::make_tuple(nullptr, -1);
    }

    auto file = fdopen(fd, "w");
    if(!file){
        memcpy(self.err, "open\0", 5);
        self.status = lbmsg::iostatus::EXCEPTION;
        return std::make_tuple(nullptr, -1);
    }

    return std::make_tuple(file,fd);
}


static void read_cbk(lbmsg::msg& self, const char* content){
    std::string str(self.content);
    std::transform(str.begin(), str.end(), str.begin(), ::toupper);



    if(str == "QUIT"){
        self.status = lbmsg::iostatus::TERM;
        return;
    }


    if(str.compare("LOGIN") == 0){
        // eg: A登录成功, 则S打开P1(回复A登录成功)
        auto pipe = self.sfile == SA ? CONNECT_PIPE_P1 : CONNECT_PIPE_P2;

        if(nullptr == get<0>(MAP[pipe])){
            MAP[pipe] = open_pipe(self, pipe);
        }
        
        // 暂时记录输出的目标管道
        self.dfile = get<0>(MAP[pipe]);
        memset(self.content, 0, lbmsg::msg::BUF_LEN);
        self.status = lbmsg::iostatus::LOGIN;
        return;
    }

#if __cplusplus >= 2020
    // 表示 用户XXX 想回复 用户NNN, 切换输出的目标管道
    str = content;
    if(str.starts_with("r:")){
        auto pipe = self.sfile == SA ? CONNECT_PIPE_P2 : CONNECT_PIPE_P1;

        if(get<0>(MAP[pipe]) == nullptr){
            MAP[pipe] = open_pipe(self, pipe);
            if(get<0>(MAP[pipe]) == nullptr){
                self.status = lbmsg::iostatus::EXCEPTION;
                return;
            }
        }
        self.dfile = get<0>(MAP[pipe]);
        str.erase(str.begin(), str.begin() + strlen("r:"));
        str = std::string("receive from") + (self.sfile == SA ? " a:" : " b:") + str;
        strncpy(self.content, str.c_str(), str.length());
        self.status = lbmsg::iostatus::WRITE;
        return;
    }
#endif
}
```

---


<img src="./assets/14_03.gif" />

---


<br/>


> 该程序只是简单实现了通信, 里面还有非常多的细节, 如实际场景中管道的替代者即为socket文件描述符; 消息格式的定义, 连接出错的处理, 断连重连, 日志记录等等.
>
> PS: 案例中采用了状态机思想(`sock.status`), 这种架构伴随着文件描述符数量较多时会出现任务不能被及时执行的问题. 即有10000个sock, 当轮询发现sock01有数据时, 修改状态为write, 则必须再循环一轮后才会被执行. 但这不能否认状态机就一无是处. 开发中要根据实际情况看是否适用该架构.

<br/>


### IO多路转接
- 现在回过头来整理一下上述案例(<font color=green>以第2个为例</font>): S进程要持有多个文件描述符, 为了实现消息的及时中转(`忽略sleep`), 它必须进行非阻塞的轮询扫描. 否则阻塞读取某1方时, 造成另一方有消息了而不能读取转发. 虽然可以通过多线程或多进程单独为其开辟一条线路处理, 但这样构架会使程序更加复杂. 除此之外该案例中, 大量的时间会消耗在扫描读取的阶段, 如果有一种方案能 <font color=deeppink>注册所有要监听的文件描述符, 然后阻塞等待, 若任何一个fd有消息了, 则被唤醒处理</font>, 幸运的是Unix提供了这种机制.

- 书籍中通过`telnet`的架构来引入IO多路转接, 笔者这里不再赘述, 其想表达的存在的问题和笔者案例中是一样的. IO多路转接(`I/O multiplexing`)的核心就是: 注册要监听的文件描述符, 阻塞等待, 当有任何一个可以进行IO时, 就可以被唤醒. 所涉及到的函数有`poll pselect select`. 后面会着重介绍linux下的`epoll`和BSD(`适用于Mac`)下的`kqueue`.


> 不同平台的差异: POSIX规定在程序中使用`select`时, 必须包括`<sys/select.h>`. 但事实上其他一些老系统上还要包括`<sys/types.h> <sys/time.h> <unistd.h>`, 所以在使用时应该看一下当前的系统环境. 在BSD(`4.2`)中IO多路转接由`select`提供, 主要用于终端IO和网络IO, 但它对其他文件描述符同样起作用. 


<br/>

### select
```cpp
#include<sys/select.h>

int select(int maxfd, fd_set* rfds, fd_set* wfds, fd_set* efds, struct timeval* timeptr);

// 成功返回此刻可以进行IO文件描述符的数量
// 出错返回-1, 并设置errno
// 超时返回0
```

> 函数作用: 分开向内核注册文件描述符. 有读,写,异常3种类型的fd. 注册的fd可以重复, 即一个fd可以同时注册为读,写或异常.
>
> 参数:
>   1. `maxfd`: 所提供的所有fd中最大值`+1`
>   2. `rfds`: 向内核注册读类型的fd, 即fd可读时select会返回(<font color=green>即使fd可以写也不会返回</font>)
>   3. `wfds`: 类比于rfds
>   4. `efds`: 现在先不讨论这种类型的fd
>   5. `timeptr`: 见下面 
>   
> 返回值: 出错时返回-1(`EINTR`), 出现的情况是select被信号打断; 超时返回0; 条件成立后返回此刻可以进行IO的文件描述符数量. 
>   - 注意对于一个fd同时注册读写, 最后返回的数量是叠加的



<br/>

- 类型`fd_set`可以类比于`sig_set`. 该类型由平台决定.
> 函数参数所指定的文件描述符集合中, 并未告诉内核有多少个fd, 所以文件描述符集合并不是单纯的数组. 可以预想到`fd_set`也类似于一个位操作一样, 后面会稍微讨论select的工作机制和优缺点. POSIX规定了对它相关的接口操作

<br/>

```cpp
#include<sys/select.h>
int FD_ISSET(int fd, fd_set* fds);      // 判断fd是否在fds中, 若存在则返回非0, 否则返回0

void FD_CLR(int fd, fd_set* fds);       // 从fds中移除fd(即不监听fd了)

void FD_SET(int fd, fd_set* fds);       // 添加fd到fds中

void FD_ZERO(fd_set* fds);              // 初始化为0 


// MacOS平台才有, 复制ofds到dfds
void FD_COPY(fd_set* ofds, fd_set* dfds);
```

<br/>

> PS: 注意0同时表示`STDIN_FILENO`的值, 但调用`FD_ZERO`后, 并不会监听`STDIN_FILENO`, 通过这些操作可以在调用select前后, 判断fd是否可以IO了

```cpp
fd_set set;
int fd;
FD_SERO(&set);
FD_SET(fd, &set);
FD_SET(STDIN_FILENO, &set);

// set注册到select中
select(xxxx)

// select返回后, 判断fd是否可以IO
if(FD_ISSET(fd, &set)){
    
}
```


<br/>

- 参数`timeptr`表示select要阻塞的时间, 即在该时间内若还没有准备好IO的fd, 将直接返回0.
> 该结构的时间精度为微秒, 这个根由OS是否支持这个精度, 若不支持则取`tv_usec`最接近的OS所支持的值
>
> 1. 指定为NULL, 表示一直等待, 直到select返回(出错或成功2种情况)
> 2. 指定`tv_sec = 0 && tv_usec = 0`, 表示不等待, 相当于前面案例中的轮询
>
> POSIX没有规定timeptr在返回时是否会被修改. 根据书籍上所说`MacOS`不会修改, Linux中在超时前返回会更新该结构, 修改为剩余时间的长度. 
>
> 当没有指定任何文件描述符集合时, 可以将select用作比sleep更高精度的睡眠函数. select所注册的文件描述符描述符一般是那些可以造成阻塞的低速IO设备(<font color=red>如网络socket, 管道, 流设备, 终端的标准输入输出等等</font>), 在BSD中同样也适用于其他文件描述符描述符, 但若是普通的文件类型几乎是直接返回.

<br/>


### select案例1-标准输入
- 标准输入在进程启动后自动打开, 并且是阻塞模式, 这里测试时将修改为非阻塞模式, 并读取一次数据, 然后通过select监听来读取标准输入
```cpp
#include<unistd.h>
#include<fcntl.h>
#include<sys/select.h>
#include<iostream>
#include<string>
#include<cerrno>

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;
    fd_set rset;
    FD_ZERO(&rset);
    FD_SET(STDIN_FILENO, &rset);

    auto osta = fcntl(STDIN_FILENO, F_GETFL);
    fcntl(STDIN_FILENO, F_SETFL, osta | O_NONBLOCK);

    // 修改为非阻塞后, 尝试读取
    // 所以会报 EAGAIN, 然后将清空cin的错误(否则后续不能再读取)
    // PS: cin最终一定是调用到read函数
    std::cin >> args;
    perror("cin");
    std::cin.clear();


    
    while(1){
        // 会阻塞在这里, 直到标准输入有数据了(用户在键盘上输入数据并摁下回车后唤醒)
        // 注意这里第1个参数的值为 注册的最大文件描述符值+1, 注册的最大描述符是STDIN_FILENO(0), 所以这里指定了1
        auto res = select(1, &rset, nullptr, nullptr, nullptr);

        // 判断假错的情况
        if(res < 0){
            if(errno == EINTR){
                continue;
            }
            perror("select");
            exit(-1);
        }

        // res > 0(因为这里只注册了一个文件描述符, 所以这里并未循环判断)
        if(res){
            // select下固定的编程模式, 返回后判断fd是否在rset中
            if(FD_ISSET(STDIN_FILENO, &rset)){
                std::string str;
                std::getline(std::cin, str);
                std::cout << str << std::endl;
            }
        }
    }

    return 0;
}
```

<br/>

```shell
./main
pid:83228
cin: Resource temporarily unavailable       # 修改STDOUT_FILENO为非阻塞的, 第1次读取(EAGAIN)
hello                                       # 进入到select阻塞, 该行在键盘上输入hello并回车
read data:hello                             # 将读取到的内容再次输出到屏幕上
world                                       # 循环阻塞后, 再次键盘上输入
read data:world                             # 再次读取回显
^C
```

<br/>

### select案例2-替换sleep
- 当没有指定任何文件描述符时, 可以将select用作更高精度的sleep
```cpp
#include<unistd.h>
#include<fcntl.h>
#include<signal.h>
#include<sys/select.h>
#include<iostream>
#include<string>
#include<cerrno>

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;

    
    struct timeval t;
    t.tv_sec = 0;
    t.tv_usec = 500000; // 50万微秒 == 0.5秒
    while(1){
        auto res = select(0, nullptr, nullptr, nullptr, &t);
        if(res < 0){
            if(errno == EINTR){
                continue;
            }
            perror("select");
            exit(-1);
        }

        std::cout << "write to screen:" << time(0) << std::endl;
    }

    return 0;
}
```

<br/>

> 程序每`0.5秒`向屏幕上输出数据, 因为`time`函数返回的是秒, 所以在打印结果中每2次是1秒

<br/>

```shell
./main
pid:83576
write to screen:1710820752
write to screen:1710820753
write to screen:1710820753
write to screen:1710820754
write to screen:1710820754
write to screen:1710820755
write to screen:1710820755
write to screen:1710820756
write to screen:1710820756
write to screen:1710820757
write to screen:1710820757
write to screen:1710820758
write to screen:1710820758
write to screen:1710820759
write to screen:1710820759
write to screen:1710820760
^C
```

<br/>


### select会修改文件描述符集合
- 要注意一点, 向select传递的参数文件描述符集合在返回后, 可能被select修改, 由于这一点, 所以每次调用select时, 必须重新指定所有的文件描述符集合

```cpp
#include<unistd.h>
#include<fcntl.h>
#include<sys/select.h>
#include<iostream>
#include<string>
#include<cerrno>

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;
    fd_set rset;
    FD_ZERO(&rset);
    FD_SET(STDIN_FILENO, &rset);


    auto afd = open("a.pipe", O_RDONLY | O_NONBLOCK);
    if(afd < 0){
        perror("open apipe");
        exit(-1);
    }
    FD_SET(afd, &rset);
    

    auto osta = fcntl(STDIN_FILENO, F_GETFL);
    fcntl(STDIN_FILENO, F_SETFL, osta | O_NONBLOCK);

    // 可以直接对 fd_set作初始化赋值
    const fd_set crset = rset;


    std::cin >> args;
    perror("cin");
    std::cin.clear();

    // 调用select前, 这个打印一定是 `has afd`
    std::cout << (FD_ISSET(afd, &rset) ? "has afd\n" : "no afd\n");

    
    while(1){
        // 最大文件描述符值是afd, 所以传递的参数是它的值再+1
        auto res = select(afd + 1, &rset, nullptr, nullptr, nullptr);

        // 判断假错的情况
        if(res < 0){
            if(errno == EINTR){
                continue;
            }
            perror("select");
            exit(-1);
        }

        if(res){
            // 当在键盘上输入内容摁下回车后, select返回前修改了 rset
            // 里面只含有 STDIN_FILENO, afd已经被移除
            if(FD_ISSET(afd, &rset)){
                std::cout << "read pipe\n";
                continue;
            }
            if(FD_ISSET(STDIN_FILENO, &rset)){
                std::string str;
                std::getline(std::cin, str);
                std::cout << str << std::endl;
                continue;
            }
        }

        // 将rset重新还原(这里直接通过赋值的方式还原)
        rset = crset;
    }

    return 0;
}
```

<br/>


### select操作普通文件
- 对于普通文件也可以使用非阻塞模式, 但基本会直接返回. 注意select内部只是监听可不可以进行IO, 它本身不会因为文件被锁住而阻塞等待
```cpp
#include<unistd.h>
#include<fcntl.h>
#include<sys/select.h>
#include<iostream>
#include<string>
#include<cerrno>

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;
    fd_set rset;
    FD_ZERO(&rset);

    auto afd = open("a.txt", O_RDONLY | O_NONBLOCK);
    if(afd < 0){
        perror("open a.txt");
        exit(-1);
    }
    FD_SET(afd, &rset);

    const fd_set crset = rset;

    char buf[100] = {0};
    while(1){
        auto res = select(afd + 1, &rset, nullptr, nullptr, nullptr);

        // 判断假错的情况
        if(res < 0){
            if(errno == EINTR){
                continue;
            }
            perror("select");
            exit(-1);
        }

        if(res){
            if(FD_ISSET(afd, &rset)){
                // 可以IO了,立即读取 ignore read-N
                auto rn = read(afd, buf, 100);
                if(rn < 0){
                    perror("read");
                    exit(-1);
                }
                std::cout << "readed\n";
                if(rn == 0){
                    std::cout << "eof\n";
                    break;
                }

                std::cout << buf << std::endl;
                __builtin_memset(buf,0, 100);
                sleep(1);
                continue;
            }
        }else{
            std::cout << "no fd can read or write\n";
            break;
        }
        rset = crset;
    }

    return 0;
}
```

<br/>

> 若有另一个进程来永久锁住`a.txt`, 该程序也会唤醒select进行读取. 要明白一点: 临界区必须由程序员调用相关的加解锁函数才会形成, 在该程序中select并不会在内部发现当前文件有锁后而自动加锁


<br/>

### select不会修改fd的属性
- select本身是阻塞的, 它并不会因为所监视的文件描述符是阻塞的而内部将其修改为非阻塞的, 然后再返回时还原. 下面的案例可以验证这一点

```cpp
#include<unistd.h>
#include<fcntl.h>
#include<sys/select.h>
#include<signal.h>
#include<iostream>
using namespace std;

static int ifd;

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;


    signal(SIGALRM, [](int no){
        cout << "signal\n";
        char buf[20] = {0};
        auto rn = read(ifd, buf, 20);       // __code_block_feature
        std::cout << "read over\n";
        if(rn){
            write(1, buf, 20);       
        }else{
            perror("read\n");
        }
    });


    ifd = dup(0);               // __code_copy_stdin
    fd_set s;
    FD_ZERO(&s);
    FD_SET(ifd,&s);
    alarm(5);                   // __code_alarm
    while(1){
        if(select(ifd+1, &s, nullptr, nullptr, nullptr) < 0){
            if(errno == EINTR){
                std::cout << "EINTR\n";
                continue;
            }
            perror("select");
            return -1;
        }
    }
    cout << "wake\n";
    int a;
    cin >> a;
    cout << "a:" << a << endl;

    return 0;
}
```

<br/>

> 上述代码中复制了标准输入`__code_copy_stdin`, 然后调用select监听IO状态. 在调用select前使用了定时器(`__code_alarm`), 希望在信号处理中以标准输入做`read`操作. 通过测试发现: select阻塞了进程, 但5秒后在信号处理中对标准输入read时, 发现是阻塞的, 说明select并不会修改fd的阻塞状态


<br/>

### select的工作机制
- 笔者这里不准备去看源码, 从用户层写一些测试代码(`MacOS平台`),然后推导出大致流程出来. 首先先看一下文件描述符集合`fd_set`

<br/>

```cpp
#include<sys/select.h>
#include<iostream>
using namespace std;

int main(int args, char** argv){
    fd_set s, b;
    std::cout << std::is_integral<fd_set>::value << std::endl;      // false  __code_int
    std::cout << sizeof(fd_set) << std::endl;                       // 128    __code_size
    s = b;                                                          // no error __code_assign
    return 0;
}
```

<br/>

> 上述代码并没有编译错误. 打印结果直接在代码中标注了.
>
> 由`__code_int`和`__code_assgin`可以推断出`fd_set`是一个结构体或联合体, 因为它不是整数但又可以直接赋值.
>
> `__code_size`的值为128字节, 刚好是`1024个bit`. 在第3章文件描述符的学习中已经了解到Unix进程的默认文件描述符数量的配置就是1024. 所以不难推断出select内部是用1个bit位来记录进程中所有的文件描述符. 下面是笔者推算出来的`fd_set`的声明

```cpp
typedef struct fd_set{
#ifdef _POSIX_OPEN_MAX
    uint8_t bit[_POSIX_OPEN_MAX];          
#else
    uint8_t bit[128];                      // right define
#endif
}fd_set;
```
> `_POSIX_OPEN_MAX`是系统定义的宏, 表示进程可以打开的最大文件数,编译器可以在编译期拿到它, 但事实上在MacOS平台上, 该值并不是128, 所以正确的定义应该类似于`uint8_t bit[128]`
>
> 结合select的原型, 只向内核提供了所有监听文件描述符中最大那个加1, 这就很明显了, 内核在发现IO状态变化后, select内部会做遍历在对应的位上标记

```cpp
select(maxfd, xxx){
    ...

    // 中断后发现IO状态发生变化(假设是文件描述符为id可以读了)
        for(int i = -1; ++i < maxfd;){
            ...

            FD_SET(id, &rfds);

            ...
        }
    ...
}
```

<br/>

> 这是笔者所做的推断并且是合理的, 从这一点来总结select的缺点:
>   1. select内部以遍历的方式反馈到用户的参数中, 所以数量较多的文件描述符发生频繁IO事件时, select的效率会明显降低
>   2. select支持的文件描述符数量有限, 最大只能支持1024. 由于`fd_set`的大小是固定的, 所以即使是修改系统配置支持更多的文件描述符, 也没用
>   3. select的原型中传递的是指针(`fd_set`), 这就注定了select内部不会对`fd_set`做copy操作(`系统调用会考虑性能的`).
>   4. 第3点虽然不会做内核态的数据拷贝, 但select原型中有5个参数(`4个指针`), 所以频繁调用select时在传递参数上会消耗大量时间( 对文件描述符监听的动作必须调用select, 并且开发中会循环调用select).
>   5. 由于select会对传递的参数做修改, 所以每一次调用select都要重新初始化文件描述符集合, 这些都会影响到效率
>   6. select的返回在用户层面处理很烦琐. select的返回值表示可以IO的fd数量, 并未告诉用户具体的fd, 所以必须是用户自己在调用select前构造数组记录全部的fd, 然后返回后遍历所有的fd做IO处理, 具体的伪代码在最后.
>
> PS: 通过以上的缺点, select并不适合做并发量大的服务器. 但若业务并发量不大且IO不频繁时可以考虑


- 这里对网络上对select的解释, 笔者发表一下见解, 先来看一下网络上的观点:
    - select内部在做盲等的轮询操作. 
    - select内部会对用户的数据做拷贝, 原因是用户态到内核态

> 首先第1点, 笔者持怀疑态度:
>   1. select是POSIX的标准, 所以基本可以确定函数的实现默认会追求性能的
>   2. select函数是阻塞的, 至少在用户代码级别是阻塞在select的. 它监听fd, fd的状态是说到底是被中断驱动的, 不管该fd是管道,socket,还是低速设备, 一定是硬件产生中断(`匿名管道由内核来产生中断`), 然后到内核, 内核再通知到进程, 内核不会做轮询操作来时时检查fd的状态.
>   3. 本人写的测试程序中观察过CPU的占用率, select下的进程是睡眠状态
>   4. 根据笔者的论述, select内部是会做遍历的, 但前提是监听到IO状态发生改变了才醒来遍历填充的
>
> 其次是第2点:
>   1. 用户态到内核态很多情况下确实会做数据拷贝, 像IO类操作的函数, 像网络连接中收发数据时. 但select这里向内核传递了指针, select的行为模式是回填修改, 它不可能复制一份到内核中先改内核中的, 再将修改到的结果复制到参数内存中. 一般内核做复制的行为是为了内核空间的安全, select的行为只是委托内核做fd状态的回调, 并不会造成内核使用用户空间的数据到内核中执行一些操作.

<br/>

- 对select返回作处理的一种方案

```txt
int fds[N] = {fd1, fd2, fd3, ...};
// 所有的fdN已经分类装入到 rfds wfds efds中
auto num = select(fdN + 1, rfds_ptr, wfds_ptr, efds_ptr, nullptr);

for(int i = -1; ++i < N && num;){
    if(FD_ISSET(fds[i], rfds_ptr)){
        // xxx
        --num;
    }

    if(FD_ISSET(fds[i], wfds_ptr)){
        // xxx
        --num;
    }

    if(FD_ISSET(fds[i], efds_ptr)){
        // xxx
        --num;
    }

    // 注意 不能 else if, 因为同样的fd, 可能同时注册了 r, w, e, 返回的num就是叠加的
}
```

<br/>


### pselect

```cpp
#include<sys/select.h>

int pselect(int maxfd, fd_set* rfds, fd_set* wfds, fd_set* efds, const struct timespec* t, const sigset_t* sig_mask);
```
> 该函数的功能和select一样, 但提供了更高精度的等待时间(`纳秒`), 当然要看系统支不支持, 不支持的话处理和select一样, 选择`tv_nsec`的值近似到当前系统支持的最大精度. 同时它支持屏蔽信号, 即在阻塞过程中不会被指定的信号打断, 返回后原子还原信号屏蔽. 若指定为NULL, 则和select一样.

```cpp
#include<unistd.h>
#include<fcntl.h>
#include<signal.h>
#include<sys/select.h>
#include<iostream>
#include<string>
#include<cerrno>

int main(int args, char** argv){
    std::cout << "pid:" << getpid() << std::endl;

    signal(SIGINT, [](int no){});
    
    struct timespec t;
    t.tv_sec = 0;
    t.tv_nsec = 500000000; // 5亿纳秒 == 0.5秒
    sigset_t set;
    sigemptyset(&set);
    sigaddset(&set ,SIGINT);
    while(1){
        auto res = pselect(0, nullptr, nullptr, nullptr, &t, &set);
        if(res < 0){
            // 不会被SIGINT唤醒
            if(errno == EINTR){
                std::cout << "int wake\n";
                continue;
            }
            perror("select");
            exit(-1);
        }

        std::cout << "write to screen:" << time(0) << std::endl;
    }

    return 0;
}
```

<br/>

```shell
./main
pid:84327
write to screen:1710822118
write to screen:1710822119
write to screen:1710822119
write to screen:1710822120
write to screen:1710822120
write to screen:1710822121
write to screen:1710822121
^Cwrite to screen:1710822122            # 产生SIGINT后, 并未唤醒进程
write to screen:1710822122
write to screen:1710822123
^C^C^Cwrite to screen:1710822123
write to screen:1710822124
^\[1]    84327 quit       ./main
```

<br/>

> pselect不会修改参数`timespec`的值. 它所存在的问题和select是一样的


<br/>

### poll
- select函数提供的接口是事件型注册, 即单位是`读,写,异常的事件发生时`. 因为select的事件机制, 对select返回后的处理必须自己构造数组通过遍历判断作处理, 这个过程还是比较烦琐的. 同时select会修改文件描述符集合, 导致每次调用select都要重新注册, 这些都是select的缺点. 所以select比较适用于监听较少的文件描述符, 事件比较单一的场景. 
- poll函数是POSIX中IO多路转接的另一种方案, 它的功能和select一样, 只是它以`fd`为单位, 在接口形式上更简单易用

```cpp
#include<poll.h>

int poll(struct pollfd fds[], nfds_t nfds, int timeout); 

// 成功返回准备好的fd数量
// 超时返回0
// 出错返回-1, 设置errno
```

<br/>

> 参数:
>   1. `fds`: 隐含的指明文件描述符集合是一个数组, 关于它的结构会在下面指出
>   2. `nfds`: 第1个参数的数量
>   3. `timeout`: 超时时间(`毫秒`)
>
> 从接口形式上来看, poll调用更加简易, 但它的精度没有select高.

<br/>

- 参数`nfds`的类型是`nfds_t`, 这是有历史原因的, 在标准前各家平台都定义了自己的类型, 所以标准为了兼容定义了`nfds_t`, 但不管怎样它是一个整数类型, 可以直接给数字, 至于它的大小不用在意.

<br/>

- 参数`timeout`
    - `0` : 表示不阻塞, 直接返回
    - `-1`: 表示永久阻塞
    - `>0`: 表示最多阻塞多少毫秒
> 同select一样, poll的其他参数为空时(`nfds为0`), 也可以当作精度较高的sleep.

<br/>

- 参数`struct pollfd`告诉内核文件描述符所关联的事件, 它的结构如下:

```cpp
struct pollfd {
     int    fd;       /* file descriptor */
     short  events;   /* events to look for */
     short  revents;  /* events returned */
 };
```

<br/>

> 其中`events`是事件, 是一个位枚举, 内核不会修改它的值, 而是在返回时回填写`revents`来表示fd的状态

<br/>


|选项|events|revents|说明|
|:-|:-|:-|:-|
|`POLLIN`|true|true|可非阻塞的读高优先级以外的数据(`POLLRDNORM | POLLRDBAND`), 即有数据可读|
|POLLRDNORM|true|true|可非阻塞的读普通数据|
|POLLRDBAND|true|true|可非阻塞的读优先级数据|
|POLLPRI|true|true|可非阻塞的读`高`优先级数据|
|`POLLOUT`|true|true|可非阻塞的写普通数据|
|POLLWRNORM|true|true|同`POLLOUT`|
|POLLWRBAND|true|true|可非阻塞的写优先级数据|
|POLLERR|false|true|已出错|
|POLLHUP|false|true|已挂断|
|POLLNVAL|false|true|fd没有引用一个打开的文件|

<br/>
<br/>

> 前4种事件是读; 中间3种是写; 最后3种是异常; 标`色`的表示常用的. events即使不指定异常事件, poll在返回时也可能在revents中填充. 下面看一下Linux中的介绍

```txt
POLLIN:
    There is data to read.

    表示有数据可以读. 不像书籍上所介绍, 此刻还可能读取高优先级数据




POLLPRI:
    There is some exceptional condition on the file descriptor.  Possibilities include:
      *  There is out-of-band data on a TCP socket (see tcp(7)).

      *  A pseudoterminal master in packet mode has seen a state change on the slave
         (see ioctl_tty(2)).

      *  A cgroup.events file has been modified (see cgroups(7)).
    
    Linux的描述的是文件描述符上有异常时:
        - tcp上的带外数据
        - 数据包模式下的伪终端主设备在从属设备上看到状态变化
        - cgroup.events文件被修改
    这里间接解释了什么是优先级高, 像tcp上的带外数据, 像读取cgroup.events文件等等




POLLHUP
    Hang up (only returned in revents; ignored in events). 
    Note that when reading from a channel such as a pipe or a stream socket, this event merely  indicates that  the peer closed its end of the channel.  
    Subsequent reads from the channel will return 0 (end of file) only after all outstanding data in the channel has been consumed.

    此选项只从revents中由内核填充, 即使在events中指定也会被忽略. 
    当从连接中读取时(如socket或管道), 当对方挂断(如socket断开,对方关闭了管道), 自己这边并不会异常断开,
    若连接中还有数据时可以继续读, 直到将数据全部读完后, 再读取后才会有eof. 即真正读完数据前是不会出错的

    PS: 以管道为例, 说白了当poll返回后, 发现 revents中含有`POLLHUP`时, 表示管道的另一端(写)关闭了, 此时尝试读取,
        若有数据则能读取出来. 不能将其反过来, 因为管道中若当前为写端时, 对方读端关闭后, 写端这里会有信号异常(后面学习管道时再讨论)

```

<br/>

```cpp
#include<unistd.h>
#include<fcntl.h>
#include<sys/poll.h>
#include<iostream>
using namespace std;

int main(int args, char** argv){
    // 以非阻塞方式打开管道
    auto afd = open("a.pipe", O_RDONLY | O_NONBLOCK);
    if(afd < 0){
        perror("open apipe");
        exit(-1);
    }

    // 先阻塞2秒(目的是其他进程先向管道中写入内容, 然后写入进程结束)
    poll(nullptr,0, 2000);      

    std::cout << "wake\n";

    struct pollfd fds;
    fds.fd = afd;
    fds.events = POLLIN;       // 注册读事件

    char buf[0x100] = {0};
    auto file = fdopen(afd, "r");
    // ignore error

    int res = 0;
    while(1){
        // 开始监听
        res = poll(&fds, 1, -1);
        if(res < 0){
            if(errno == EINTR){
                continue;
            }
            perror("poll");
            exit(-1);
        }

        // 被唤醒
        if(res){

            // 对方管道关闭了, 要尝试读取一下管道中的内容
            if(fds.revents | POLLHUP){
                std::cout << "对方断开了, 尝试读取\n";
            }

            // 对方写入了数据
            if(fds.revents | POLLIN){
                std::cout << "有内容了, 读取\n";
            }
            auto fread_res = fgets(buf, 0x100, file);
            if(fread_res){
                // ignore error
                cout << buf << endl;
            }
            break;
        }
    }
    return 0;
}
```

<br/>

> 以管道来说, 当对方写入了内容到管道然后自己挂断, 则`POLLHUP和POLLIN`会都被标记. poll相较于select在使用上更简单. 它解决了:
>   1. 文件描述符数量的问题
>   2. 参数复制问题, 不需要每次都重新初始化
>   
> PS: 它并未解决内部循环填充的问题, 对于大量文件描述符的频繁IO时, 效率仍会明显降低. 


<br/>


### epoll
- epoll是linux上独有的实现, 它并不是简单的封装`poll`, 可以执行与`poll`类似的任务. 可以配置`边缘触发接口`, 也可以配置`级别触发接口`. 能很好的扩展到大量的文件描述符. 这一点是从Linux中的man手册中摘抄的. 这里先不要管`边缘触发`和`级别触发`. 先来看一下相关的函数

<br/>


- <font size = 5>创建epoll实例</font>

<br/>

```cpp
// 注意是在linux环境下才有
#ifdef __linux__        

#include <sys/epoll.h>

int epoll_create(int size);     
int epoll_create1(int flags);

// 成功返回文件描述符(>0)
// 出错返回-1, 并设置errno
#endif
```

<br/>

> 在linux中它们是系统调用, 函数的返回值只是内核数据结构的引用, 后续用作epoll的所有操作.在前面大量的api中都可以发现, 内核提供给外界所引用的基本都是整数, 原因是计算机处理整数的速度快. 
>   `epoll_create`的内核版本要求`2.6`, glibc的版本要求`2.3.2`
>   `epoll_create1`的内核版本要求`2.6.27`, glibc的版本为`2.9`
> 
> 参数:
>   `size`: 告诉内核监听多少个fd, 以便内核创建合适的内存, 该值只是一个建议, 内核可能创建更大的空间.  在linux2.8以后, 该参数是忽略的, 内核会动态调整空间, 但必须提供`>0`的值. 
>   `flgas`: 为0则表示与`epoll_create`一样的效果. 可以指定`EPOLL_CLOEXEC`选项, 与`FD_CLOEXEC`一样的效果, 当exec变为其他的进程后, 该fd不会关闭(`具体看第3章`)
>
> PS: 这里比较有趣的是返回的是一个文件描述符, 这里多一点扩展: Unix中的文件系统说白了是管理磁盘的软件, 系统启动后内核会建立相关的数据结构来维护当前磁盘, 当然文件系统的初始化的相关数据也一定记录在了磁盘中, 可以理解为文件系统的配置文件. 文件描述符本质是运行在内存中的文件系统描述磁盘上某段空间的一个实例引用. 很多时候一个文件描述符对应着实际物理磁盘中的空间, 但事实上Uinx文件系统中可以创建虚拟的文件(`没有在磁盘上存在的`), 如匿名管道. `epoll_create`本质也是创建了一个虚拟文件, 通过文件描述符可以引用到它. 那既然是fd, 那能否调用相关的IO函数? 下面来测试一下效果


<br/>

```cpp
#include<unistd.h>
#include<sys/epoll.h>
#include<sys/stat.h>
#include<fcntl.h>
#include<climits>
#include<iostream>

using namespace std;


int main(){
	auto efd = epoll_create(1);
	if(efd < 0){
		perror("epoll_create");
		exit(-1);
	}

	struct stat sta_buf = {0};
	fstat(efd, &sta_buf);
	cout << "hard link:" << sta_buf.st_nlink << endl;
	cout << "inode:" << sta_buf.st_ino << endl;

    // 通过fd查找文件名
	do{
		  char buf[1024] = {'\0'};
		  char file_path[PATH_MAX] = {'0'};
		  snprintf(buf, sizeof (buf), "/proc/self/fd/%d", efd);
		  auto res = readlink(buf, file_path, sizeof(file_path) - 1);
		  if(res < 0){
			  perror("read link");
		  }else{
			  std::cout << "path: \"" << file_path << "\"\n";
		  }

	}while(0);

	char buf[1024];
	auto rn = read(efd, buf, 1024);
	if(rn < 0){
		perror("read efd");
		exit(-1);
	}

	if(rn == 0){
		std::cout << "read over\n";
	}
	if(rn){
		std::cout << "read data:" << buf << std::endl;
	}

	close(efd);
}
```

<br/>

> 测试结果如下:

```shell
sudo ./main                         # 以root权限运行该程序
hard link:1
inode:11341
path: "anon_inode:[eventpoll]"      # anonymous 匿名的意思
read efd: Invalid argument
```

<br/>

> 可以看到efd就是一个虚拟文件, 它没有真实的磁盘空间, 但在文件系统中有硬链接,inode码, 不能对它进行读写. 对于它的操作只有内核才有权限. 像其他文件描述符一样, 也是在不用是关闭它. 

<br/>

- <font size = 5>管理文件描述符</font>

> linux公开了一个单独的函数来注册,修改,移除监听的文件描述符. 这一点的用法同`fcntl`一样

```cpp
#ifdef __linux__
#include<sys/epoll.h>

int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

// 成功返回0
// 出错返回-1, 并设置errno

#endif
```

<br/>

> 参数:
>   `epfd`: epoll实例, 由`epoll_create`返回
>   `op`: 对epoll操作的行为, 见下面
>   `fd`: 要注册的文件描述符
>   `event`:见下面

<br/>

> 动作`op`

<br/>

|选项|说明|
|:-|:-|
|`EPOLL_CTL_ADD`|添加fd到epoll实例中(<font color=green>事件由第4个参数指定</font>)|
|`EPOLL_CTL_MOD`|修改epoll中的fd的事件(<font color=green>第4个参数指定</font>)|
|`EPOLL_CTL_DEL`|删除epoll中的fd, 即移除监听|

<br/>

> 事件`event`

```cpp
typedef union epoll_data {
   void        *ptr;
   int          fd;
   uint32_t     u32;
   uint64_t     u64;
} epoll_data_t;

struct epoll_event {
   uint32_t     events;      /* Epoll events */
   epoll_data_t data;        /* User data variable */
};
```

<br/>


|选项|说明|
|:-|:-|
|EPOLLIN|同POLLIN|
|EPOLLOUT|同POLLOUT|
|EPOLLRDHUP|这个值在后面学习到socket时详细探究|
|EPOLLPRI|同POLLPRI|
|EPOLLERR|关联的fd发生错误时被触发; 读端关闭后管道的写端也会触发该事件. 其中第2种情况也视为出错. 用户不需要在ctl中指定该事件, 该事件由`epoll_wait`回填|
|EPOLLHUP|见后面|
|EPOLLET|边缘触发模式, 调用`epoll_wait`时,只当fd的状态发生改变时触发一次事件|
|EPOLLLT[^ann-epoll-level]|级别(`电平`)触发模式, 调用`epoll_wait`时,只要fd的缓冲区有数据没读完就会触发|
|EPOLLONESHOT|只触发一次事件, 后续不会触发. 可以再调用`epoll_ctl`重新注册[^ann-epoll-ctl-0]事件|
|EPOLLWAKEUP|确保系统在特定条件下不休眠[^ann-epoll-wakeup]|
|EPOLLEXCLUSIVE|它用于并发时的唤醒策略, 后面会有章节来详细讨论(`同时有select和poll`)|


<br/>

- <font size = 5>epoll阻塞等待</font>

```cpp
#include <sys/epoll.h>
int epoll_wait(int epfd, struct epoll_event *events,
              int maxevents, int timeout);
int epoll_pwait(int epfd, struct epoll_event *events,
                  int maxevents, int timeout,
                  const sigset_t *sigmask);

// 成功返回 准备好的IO数量
// 超时返回0
// 出错返回-1, 并设置errno
```

<br/>

> 参数:
>   1. `epfd`: 由`epoll_creat`创建的实例
>   2. `events`: 数组, 当`epoll_wait`返回后,会将原来对`fd`注册信息回填到数组中, 也就是说该数组存储了所有准备好IO的fd事件集合
>   3. `maxevents`: 数组的长度
>   4. `timeout`: 毫秒. 当指定`-1`, 表示永久阻塞. 指定`0`会立即返回. 指定`>0`的值表示最多阻塞多少毫秒
>   5. `sigmask`: 在阻塞期间不被指定的信号打断唤醒, 唤醒后原子的还原信号
>
> PS: 不能将其当作sleep函数来用. 使用`epoll_wait`时发生出错时要检查`EINTR`, 这视为一种假错. 和select, poll的行为一样, epoll不管注册的fd是否是阻塞的, 它本身会阻塞监听fd的可IO状态.

<br/>

### epoll选项`EPOLLHUP`
- 以管道为例,当写端断开时, 读端会收到该事件, eg:
    1. 注册读事件(`EPOLLIN`)
    2. 写端持续写数据到管道中
    3. 在写端写入的过程中读端会收到`EPOLLIN`,读取管道中的内容.
    4. 写端关闭, 读端会收到`EPOLLHUP`, 此时管道若还有数据, 则可以继续读取, 并且调用`epoll_wait`后不会出错, 会继续触发`EPOLLHUP`. 所以作为读端应该在发现读完数据后, 主动移除事件
> 不需要在注册时指定该选项, 它由`epoll_wait`自己填充

<br/>

```cpp
#include<unistd.h>
#include<sys/epoll.h>
#include<sys/poll.h>
#include<sys/stat.h>
#include<fcntl.h>
#include<climits>
#include<iostream>
#include<sstream>

using namespace std;

static void print_e(const epoll_event& e){
	ostringstream str;
	str << "\n@@@\n";
	if(e.events & EPOLLIN){
	    	str << "epoll_in\t";
	}
	if(e.events & EPOLLERR){
	    	str << "epoll_err\t";
	}

	if(e.events & EPOLLHUP){
		str << "epoll_hup\t";
	}
	str << "\n@@@\n";
	std::cout << str.str();
}

int main(){
	auto efd = epoll_create(1);
	if(efd < 0){
		perror("epoll_create");
		exit(-1);
	}
	auto afd = open("./a.pipe", O_NONBLOCK | O_RDONLY);
	epoll_event e;
	e.events = EPOLLIN;
	e.data.fd = afd;
	epoll_ctl(efd, EPOLL_CTL_ADD, afd, &e);

	struct epoll_event ebf;
	char buf[20] = {0};
	while(1){
		auto res = epoll_wait(efd, &ebf, 1, -1);        // __code_ewait
		if(res > 0){
			print_e(ebf);                               // __code_pe
			if(read(afd, buf, 20) == 0){                // __code_eof
				std::cout << "eof\n";
                // 可以移除afd的监听
			}
			std::cout << buf << flush;                  // __code_content
			__builtin_memset(buf, 0, 20);
		}else if(res < 0){
            if(errno == EAGAIN){
                continue;    
            }
			perror("epoll_wait");
			exit(-1);
		}else{
			// 超时(本例中不会返回这种情况)
		}
		poll(nullptr, 0, 1000);                         // __code_sleep
	}
	close(efd);
	return 0;
}
```

<br/>

> 上述程序通过管道来测试. 程序作为管道的读端, 以非阻塞模式打开等待写端写入内容. 初始化后`__code_ewait`并不会因为没有写端而出现事件的回调. 当写端接入后, 并写入了数据则`__code_ewait`会触发事件EPOLLIN(`__code_pe`). 然后从管道中读取后打印数据(`__code_content`). 程序中对eof只做了打印处理, 这是为了测试. 还有一点, 程序中在`__code_ewait`返回后, 直接取的`afd`, 事实上可以从`ebf.data.fd`取得文件描述符, 这里为了方便, 没写那么严谨
>
> 测试模式是通过shell完成的, 通过向管道中键入内容触发程序的事件回调, 因为shell中的命令完成后,进程结束导致管道关闭,所以程序中会触发`EPOLLHUP`的事件, 这并不是一个错误, 所以此刻后若没有管道再次接入, `__code_ewait`将会一直触发该事件. 这和初始化时的情况不一样(`初始化时若没有写端, 也不会有任何事件`), 因为管道的状态已经有过写者了, 后续写者的断开是管道的一个状态

<br/>

---

<img src="./assets/14_04.gif" />

---

<br/>

> 测试中分别间隔的向管道中写入数据, 每一次的命令会睡眠3秒, 这样测试的结果就会很明显的打印出`EPOLLHUP`的状态


<br/>

### epoll触发策略
- 默认情况下的触发策略是电平触发(`level-triggered`), 表示只要fd的缓冲区有数据, 调用`epoll_wait`就会触发该事件. 这种策略模式在效果上和poll是等价的, 效率要高于poll. 另一种触发策略是边缘触发的(`edge-triggered, 笔者理解为懒惰模式`), 只有当fd的状态改变时调用`epoll_wait`才会触发, 这样会导致若一次没有读完缓冲区内容, 则再次调用`epoll_wait`后会阻塞. 这样的目的是减少内核事件回调, 提高效率, 相应的用户层面的缓冲区处理在此策略下就比较复杂.
- 边缘触发机制决定了`EPOLLET`的用法原则:
    1. 所监视的fd最好为非阻塞的
    2. 调用`epoll_wait`的时机应该在`read或write`后出现`EAGAIN`的情况

> 边缘策略中用户应该尽量将缓冲区的内容读取完毕. 当在后面学习到socket不同主机进程间通信后还要将该策略拿出来做探究. 这里只写一个简单的案例来演示这2种策略的区别. 下面的程序其实就是对前一小节程序稍作修改. 通过在标准输入上来测试.

<br/>

```cpp
#include<unistd.h>
#include<sys/epoll.h>
#include<sys/poll.h>
#include<sys/stat.h>
#include<fcntl.h>
#include<climits>
#include<iostream>
#include<sstream>

using namespace std;

static void print_e(const epoll_event& e){
	ostringstream str;
	str << "\n@@@\n";
	if(e.events & EPOLLIN){
	    	str << "epoll_in\t";
	}
	if(e.events & EPOLLERR){
	    	str << "epoll_err\t";
	}

	if(e.events & EPOLLHUP){
		str << "epoll_hup\t";
	}
	str << "\n@@@\n";
	std::cout << str.str();
}

int main(int args, char** argv){
	if(args < 2){
		std::cerr << "usage ./main <1:ET策略, 0:LT策略>\n";
		exit(-1);
	}

	bool et = atoi(argv[1]) == 1;
	std::cout << "使用:" << (et?"ET":"LT") << "策略\n";

	auto efd = epoll_create(1);
	if(efd < 0){
		perror("epoll_create");
		exit(-1);
	}
	auto afd = STDIN_FILENO;
    auto o_sta=fcntl(afd, F_GETFL);
    fcntl(afd, F_SETFL, o_sta | O_NONBLOCK);    // 修改为非阻塞
	epoll_event e;
	e.events = EPOLLIN;
	if(et){
		e.events |= EPOLLET;
	}
	e.data.fd = afd;
	epoll_ctl(efd, EPOLL_CTL_ADD, afd, &e);

	struct epoll_event ebf;
	char buf[3] = {0};
	ssize_t rn = 0;
	while(1){
		auto res = epoll_wait(efd, &ebf, 1, -1);
		if(res > 0){
			print_e(ebf);
			rn = read(afd, buf, 2); // 只读取2个字符, 第3个字符为\0结束, 便于输出观察
			if(rn == 0){
				std::cout << "eof\n";
			}else if(rn < 0){
				if(errno == EAGAIN){
					std::cout << "loop epoll_wait\n";
					continue;
				}
				perror("read");
				exit(-1);
			}else{
                // TODO: 这里省略了一次性读取完缓冲区的逻辑
				std::cout << "\ncontent: " <<  buf << flush;
				__builtin_memset(buf, 0, 3);
			}
		}else if(res < 0){
            if(errno == EINTR){
                continue;
            }
			perror("epoll_wait");
			exit(-1);
		}else{
			// 超时(这里不会返回这种情况)
		}
	}
	close(efd);
	return 0;
}
```

<br/>

> 该程序中通过命令行参数确定使用策略. 本程序在shell中测试, 并未测试eof的情况(键入`ctrl + d`). 也没有出现`EAGAIN`的情况, 若要测试这种错误则将程序修改为打开管道文件, 再另写一个进程来向管道中写入内容, 当本例中的进程将所有的内容读取完毕后, 再次读取则会报`EAGAIN`错误. 
>
> 程序中缓冲区大小为3, 但读取时只读取2个字节, 这样的目的在于字符串的`\0`结束, 以便输出时屏幕显示的是正常的.
> 
> 经过测试, 当指定电平策略(`./main 0`)时, 一次性键入5个字符, 程序中`epoll_wait`会唤醒3次, 直到将缓冲区的5个字符读取完毕. 若指定边缘模式(`./main 1`)则, `epoll_wait`只会唤醒1次. 输出的3次结果是因为每次读取完毕后发生阻塞, 笔者再次摁下了`Enter`键, 这样会触发`epoll_wait`. 测试结果在下面的动态图中. 对于边缘模式下缓冲区数据没有读完时`epoll_wait`不能触发的问题, 用户所要做的就是一次性读取完, 在本例子中并没有去实现它.

<br/>

---

<img src="./assets/14_05.gif" />

---


<br/>
 

```txt
edge-triggered的使用原则的原因:
    第1条: 因为epoll实例中可能注册了很多fd, 当某个注册的fd是阻塞模式时会导致epoll_wait返回后
           fd作IO操作时若阻塞住进程, epoll_wait就不能正常的工作, 因为在阻塞期间其他fd的状态已经发
           生了改变, 而得不到通知
           
           PS: 其实使用epoll时, 不管是level还是edge, 都应该设置为非阻塞模式


    第2条: epoll_wait返回后, 非阻塞fd做完了IO操作, 当出现`EAGAIN`后, 表示缓冲区没有内容或缓冲区已满,
           当缓冲区满了后, 写端就不会发送数据, 这样下一次可写并且发送数据到读端时, 读端这里一定会触发事件(新数据到来fd的状态会发生变化)
           当缓冲区空了后, 表示读端这里已经将数据读取完毕, 等待写端继续写入数据, 此刻就可以调用epoll_wait等待状态回调
```

<br/>

### epoll一次性监听
- `EPOLLONESHOT`选项只触发一次事件, 所以当结合`EPOLLET`的边缘模式时, 尤其要注意
    1. 一定要处理它缓冲区的内容, 否则该fd后续将永久不被触发
    2. 或者发生事件后, 重新调用`epoll_ctl`修改一下(`EPOLL_CTL_MOD`)

> 下面的案例演示了`EPOLLET`及`EPOLLONESHOT`时, 使用标准IO读取完所有的字节的处理, 里面有很多标准IO的细节以及C字符串要注意的地方

<br/>

```cpp
#include<unistd.h>
#include<sys/epoll.h>
#include<iostream>

using namespace std;

int main(int args, char** argv){
	auto efd = epoll_create(1);
	auto afd = STDIN_FILENO;                        // __code_0
    auto o_sta = fcntl(afd, F_GETFL);
    fcntl(adf, F_SETFL, o_sta | O_NONBLOCK);
	auto af = fdopen(afd, "r");                     // __code_1

	epoll_event e;
	e.events = EPOLLIN | EPOLLET | EPOLLONESHOT;    // __code_2
	e.data.ptr = af;                                // __code_3
	epoll_ctl(efd, EPOLL_CTL_ADD, afd, &e);

	constexpr int BUF_SIZE = 100;                   // __code_buf_size
	char buf[BUF_SIZE] = {0};                       

	struct epoll_event ebf;                         // __code_ebf

	while(1){
		auto res = epoll_wait(efd, &ebf, 1, -1);    // __code_4
		if(res < 0){
            if(errno == EINTR){
                contitue;
            }
			perror("epoll_wait");
			exit(-1);
		}

                                                    // __code_5
		if(fgets(buf, BUF_SIZE, static_cast<FILE*>(ebf.data.ptr))){
            // 这里读取操作应该循环读, 直到eof, 这里就直接省略了该流程.
            // 加上程序中指定了EPOLLONESHOT, 所以要在eof的情况下, 重新注册
			std::cout << "\ncontent: " <<  buf << flush;    // __code_print_content
			continue;
		}

		if(ferror(static_cast<FILE*>(ebf.data.ptr))){
			if(errno == EAGAIN){                    // __code_6
				std::cout << "loop epoll_wait\n";   // __code_false_error
	            //epoll_ctl(efd, EPOLL_CTL_MOD, afd, &e); // 修改一下
			}else{
				perror("fgets");
				exit(-1);
			}
		}
		if(feof(static_cast<FILE*>(ebf.data.ptr))){ //__code_7
			std::cout << "eof\n";
	        //epoll_ctl(efd, EPOLL_CTL_MOD, afd, &e); // 
		}
	}
	close(efd);
	return 0;
}
```

<br/>

> 程序中使用的是策略是边缘触发模式, 并且只监听一次. 所以当标准输入的字节超过100时, 最多只会读取100字节的内容 
>
> `__code_0`: 这里为了方便直接获取标准输入的常量值
> 
> `__code_1`: 转化为流对象并记录在变量`e`中, 因为`struct event_buf`结构中的data部分是一个`union`, 用户在注册时可以将自定义相关的信息记录在里面, 前面的案例中都是将`fd`保存起来, 这里直接记录了对应的file对象. 当`epoll_wait`返回后, 会将信息回填到`ebf`中, 从而取到流对象
>
> `__code_5`: 直接使用标准IO函数获取内容. 需要说明的是fgets会在读取内容的最后附加字符串的尾0(`详见fgets函数`), 所以严格来说`__code_print_content`是错误的, 因为第100字节并不代表一个完整的内容, 比如汉字的情况时可能第100个字节只是汉字编码存储中的一部分.
>
> `__code_6`: 是监听假错误的情况
>
> `__code_false_error`: 因为指定了`EPOLLET`, 所以应该在这里重新调用`epoll_ctl`对afd重新注册.但为了测试效果, 这里没有调用. 同时程序中又使用了`EPOLLONESHOT`, 也应该在读取完所有的数据后, 重新注册.
>
> `__code_7`: 读取结束的情况
>
> 下面是测试过程:

<br/>

```shell
# __shell_0
echo $(for i in {0..9}; do echo {0..9}; done) | tr -d ' ' | tr -d '\n' | ./main     

# __shell_1
content: 012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678    

# __shell_2(键入了换行)
aoehuaouh       # 在键盘上输入的字符串


```

<br/>

> `__shell_0`: 构造一个100字节大小的内容, 并通过管道重定向`main`进程的标准输入. 
>
> `__shell_1`: `main`进程从标准输入得到的内容, 发现只获取了99字节. 程序中指定的是获取100字节, 原因就是标准IO的fgets函数. shell提供了100字节的内容, fgets(标准IO)调用系统IO一次性读取超过指定数量的100字节内容放到自己的IO缓冲区中, 然后从该缓冲区读内容到buf中, 并将第100字节的内存填充为尾0, 所以最后第100字节的内容其实没有读完. 所以这里就是要注意的地方: 在程序中使用的标准IO, 事实上已经将内核缓冲区的100字节读完, 只是fgets函数的特性, 显示到屏幕上的内容是99字节. 在实际开发中, 应该继续读取直到eof(`程序中并未实现`)
>
> `__shell_2`: 是笔者手动键入了换行, 发现并未有任何效果, 后续在键盘上键入内容后进程也没有任何反应, 这里有2个原因:
>   1. `EPOLLONESHOT`:  因为响应一次事件后,后续将不会再响应(代码中没有重新注册)
>   2. 程序的标准输入被重定向成了管道, 所以键盘事件对`epoll_wait`没有影响
>
> 写一个简单的案例来测试这一点:

<br/>

```cpp
#include<unistd.h>
#include<sys/types.h>
#include<fcntl.h>
#include<signal.h>
#include<sys/epoll.h>
#include<iostream>

using namespace std;

static FILE* af;

int main(int args, char** argv){
	auto efd = epoll_create(1);

    // 以读写方式打开
	auto afd = open("a.pipe", O_RDWR | O_NONBLOCK);

    // 主要逻辑, 用来读取管道的内容
	af = fdopen(afd, "r");

	epoll_event e;

    // 这里当没有选择 EPOLLONESHOT时, 表明后续afd的状态发生改变时, 事件还会触发
    // 即下面的 alarm信号处理中, 对管道写入一个字符, 这样就会触发 epoll_wait
	e.events = EPOLLIN | EPOLLET; //| EPOLLONESHOT;
	e.data.ptr = af;
	epoll_ctl(efd, EPOLL_CTL_ADD, afd, &e);

	constexpr int BUF_SIZE = 100;
	char buf[BUF_SIZE] = {0};

	struct epoll_event ebf;

	signal(SIGALRM, [](int no){
        // 等待5秒后, 向管道写入数据, 使afd的状态发生变化
        // 需要说明的是这里不要使用 fput("@", af):
        ////  af的任务只是单纯的读取, 标准IO机制有自己的缓冲区, 所以当同时读写时,缓冲区会混乱
        //// 所以直接调用系统IO来写入数据
		write(fileno(af), "@", 1);
	});

	alarm(5);

	while(1){
		auto res = epoll_wait(efd, &ebf, 1, -1);
		if(res < 0){
			if(errno == EINTR){
				continue;
			}
			perror("epoll_wait");
			continue;
		}

        // 这里为了测试出缓冲效果, 没有一次性读完内容
		if(fgets(buf, BUF_SIZE, static_cast<FILE*>(ebf.data.ptr))){
			std::cout << "\ncontent: " <<  buf << flush;
			continue;
		}
		if(ferror(static_cast<FILE*>(ebf.data.ptr))){
			if(errno == EAGAIN){
				std::cout << "loop epoll_wait\n";
			}else{
				perror("fgets");
				exit(-1);
			}
		}
		if(feof(static_cast<FILE*>(ebf.data.ptr))){
			std::cout << "eof\n";
		}
	}
	close(efd);
	return 0;
}
```

<br/>

> 程序主要是测试标准IO的缓冲机制, 测试步骤:
>   1. 运行程序
>   2. 在其他shell中向`a.pipe`写入100个字节
>   3. 程序立即输出99个字节的数据. 事实上内核缓冲中的100个字节已经被读完, 只是标准IO机制, 还有第100处的这个字节没有从标准IO的缓冲区中读出来, 又因为使用的是`EPOLLET`策略, 所以必须使文件描述符`afd`的状态发生改变, 所以程序5秒后, 在信号处理中又主动向管道中写入了1个字节(`@`), 当信号程序被调用完毕后, 此刻`epoll_wait`被唤醒是假错, 继续回到循环睡眠, 同时发现afd管道又有了新内容`@`, 于是又醒来, 接着调用`fgets`, 标准IO先从自己的缓冲区将上一次第100个字节处的`9`读出来放到buf中, 并继续从内核缓冲区中将`@`读取出来到缓冲中, 同时又存读到buf中, 所以5秒后打印了`9@`


<br/>

---

<img src="./assets/14_06.gif" />

---


### epoll原理
```txt
epoll的核心是epoll实例, 它是内核创建的数据结构(其核心是红黑树, 和一个链表), 
从用户层面来看, 可将其视作两个列表容器:
    1. 要监听的文件描述符集合
    2. 准备好可以IO的文件描述符集合, 由内核填充

使用epoll的3步:
    1. 创建epoll实例
    2. 注册要监听文件描述符(也可修改,移除)
    3. 等待IO事件返回

可以明显看到整个过程就是IO多路转接流程, 但epoll将步骤分开了. 

epoll的工作机制:
    0. 创建epoll实例
        > 内部直接初始化了红黑树, 和事件链表

    1. 用户注册fd以及对应的event到红黑树中. 其中fd做为key, event作为value(结点). 

    2. 当fd对应的IO状态发生变化时, 直接在红黑树中通过fd找到value结点, 然后将该fd以及事件记录到链表中

    3. 当用户调用epoll_wait时:
        > 内部直接看链表是不是空, 若是空则阻塞等待.
        > 若不是空, 先将链表中记录的fd以及对应的事件复制到参数的空间中, 然后直接返回. 
            注意这里笔者只是简单的描述这个过程, 内部实现的效率决不是简单的扫描复制回填


    PS: 其中第2步准确来说是异步的, 因为当用户注册了文件描述符事件时, 就已经开始监听了.
        这其中的查找速度非常快, 这是基于红黑树的快速查找特性. 

        第3步调用epoll_wait时发现没有IO状态的记录时才会阻塞. 但不管怎样epoll_wait始终会
        复制结果数据到用户空间中. 
        网络上很多博主解释epoll内部会创建共享内存, 个人是不同意的, 因为所有epoll函数没有
        从内核返回空间. 即使是epoll_wait的第2个参数, 也是用户自己的空间

        man手册提到epoll_wait参数所提供的时间可能会超出, 这是由于内核调度的延迟. 
        事实上这同样会发生在select和poll函数中


对比select和poll:
    1. epoll解决了文件描述符数量的限制

    2. epoll将IO多路转接分解成了3步走, 降低了系统调用次数(逻辑上用户只需要循环调用epoll_wait)

    3. epoll正因为分开了注册和监听的步骤, 才体现了异步通知的机制
        > 即在没有调用epoll_wait前, 可能此时已经有fd可以IO了

    4. 内部不再是通过遍历所有的文件描述符做筛选, 而是通过红黑树
        快速定位到fd, 这个过程非常快, 然后直接记录

    PS: 因为epoll的特性, 要时时监听文件描述符则要循环调用epoll_wait



epoll的触发策略
    Level-triggered: 级别触发(电平触发)
        即只要发现有数据可IO, 调用 epoll_wait就会触发返回. 其实它的效果就是加快版本的poll

    edge-triggered: 边缘触发
        只有IO的状态发生变化了才触发, 如管道中写入了2kb的数据, 触发这一次事件,
        当调用 epoll_wait后返回, 读取1kb数据后, 管道中还有1kb的数据没有读完, 
        若再调用epoll_wait后也是不会返回的. 

    边缘触发是为了更加提高效率(减少内核软中断的次数), 这要求了在该策略下用户应在epoll_wait返回
    后尽量处理完所有的数据
```

<br/>


### IO多路转接与并发
- 这里之所以要探究这些, 主要是为了清楚的了解并发模式下, IO多路转接的所存在的问题. 特别是epoll的`EPOLLEXCLUSIVE`选项. 这能为在并发场景下效率的优化做到方向上的指导.
- 首先要接触一个概念<font color=deeppink>惊群</font>: 直白点就是多个线程或进程等待同一条件时, 条件成立后有多少线程或进程被唤醒, 若唤醒数量大于1, 则就是惊群. 当并发量小的时候惊群所引发的效率问题还不足以明显, 但规模到达某一阈值时, 问题就出来了. 
- 为了开始探究, 先分别回顾几种线(进)程间的通信同步:
    1. 文件锁
    2. 信号(`sigsuspend, sigwait, kill, pthread_kill`)
    3. 线程互斥锁

> 现在要来测试这3种同步有没有惊群效果. 首先要明白一点等待的同一条件是什么. 在代码层面就是锁. 对于信号来说,条件就是多线程下注册的相同信号处理, 调用`kill`是否唤醒多条线程, 这一点已经在第前面的线程章节测试过了, 只能唤醒一条, 但并不能说明信号唤醒线程在真实的内核中是否是惊群, 可能唤醒了多条, 但没抢到锁的线程可能又重新睡眠了, 这个过程发生在内核中, 如果是这样的话, 信号本质还是惊群, 只是没有体现在用户层面, 所以笔者这里定义惊群的范围是用户层面的, 以信号来说, 在用户看来只有一条线程被唤醒, 所以认定为非惊群的. 这里测试一下文件锁和互斥锁来说明什么是惊群

<br/>


```cpp
#include<unistd.h>
#include<sys/stat.h>
#include<sys/types.h>
#include<sys/fcntl.h>
#include<sys/wait.h>

#include<iostream>
#include<cstring>

using namespace std;


#ifdef MUTEX

#include<thread>
#include<mutex>
#define LOCK() 		m.lock()
#define UN_LOCK() 	m.unlock()
static std::mutex m;

#elif defined(FILE_LOCK)

#include<sys/file.h>
#define LOCK() 		flock(fd, LOCK_EX)
#define UN_LOCK() 	flock(fd, LOCK_UN)
static int fd;

#else

#error 没有锁

#endif

static void oper_file(const char* txt_path){
#if defined(MUTEX)
	// 多线程模式下, 
	auto
#endif
	fd = open(txt_path, O_RDWR);

	LOCK();

#if defined(MUTEX)
	std::cout << "tid:" << pthread_self() << endl;
#elif defined(FILE_LOCK)
	std::cout << "pid:" << getpid() << endl;
#endif

	char buf[20] = {0};
	read(fd, buf, 20);
	auto num = atoi(buf);
	std::cout << "num:" << num << endl;
	num += 1;
	snprintf(buf, 20, "%d", num);
	lseek(fd, 0, SEEK_SET);
	write(fd, buf, strlen(buf));

	sleep(1);

	UN_LOCK();

	close(fd);
}

int main(int args, char** argv){
	for(int i = 0; ++i < 11; ){

#if defined(MUTEX)
		thread(oper_file, argv[1]).detach();
#elif defined(FILE_LOCK)
		if(fork() == 0){
			oper_file(argv[1]);
			exit(0);
		}
#endif
	}

#if defined(MUTEX)
	sleep(11);
#elif defined(FILE_LOCK)
	for(int i = -1; ++i < 10;){
		wait(NULL);
	}
#endif
}
```

<br/>

> 上述代码用宏区分当前环境是多线程还是多进程. 多线程时使用了mutex(<font color=green>C++标准库的mutex调用到底层phread相关的互斥锁</font>).多进程使用了文件锁. 在临界区(`LOCK与UN_LOCK`)所要做的是从文件中读取内容做加1操作后写入到文件, 其中特意睡眠了1秒. 从测试打印中可以发现, 当解锁后只有1条线程或进程被唤醒. 这当然是符合常理的, 但不能从这一点来推断出文件锁内部是不是惊群了, 可能唤醒了所有的进程, 然后只有1条进程抢到了锁, 其他进程则抢到锁失败导致又睡眠. 但互斥锁一定是不惊群的, 因为在第`11_12`章线程的章节中, 已经分析了源码, 互斥锁内部调用了`futex_wait(Linux)`, 这个系统调用详细说明了, 只会唤醒1条线程. 惊群的效果在互斥锁中通过条件变量的接口可以很明确的测试出来`pthread_cond_broadcast`. 文件锁是不是惊群的笔者自己还不能写代码确定, 但手册中说现在的flock函数已经实现为了系统调用和`fcntl`上锁是分开的, 既然是系统调用, 则内核应该是效率较高的非惊群的, 同时笔者也在网上查阅了资料, 像nginx使用过文件锁来防止惊群, 并且以笔者对惊群的定义, 认为文件锁也是非惊群的

<br/>

---

<img src="./assets/14_07.gif" />

---


### 文件锁


### IO多路转接时普通文件
- 在最开始进行IO多路转接时, 曾经提到过: 对于监听普通文件时, select, poll, epoll都会迅速返回, 所以设置阻塞标记于否没有用, 但学习了文件锁后, 必须要讨论在强制性锁的情景.  

### kqueue











[^ann-pipe-0]: 单工不是说管道的一端不能同时进行读\写, 而是说在逻辑上数据流向是单向的. 不管是匿名或命名的管道在程序上都可以在一端进行读写, 但逻辑上想要实现的是数据从一方传送到另一方, 若一个进程同时读写管道, 那数据的流动将只在该进程中,看上去没多大用(<font color=green>但也可利用管道在多线程环境中进行线程间通信</font>)

[^ann-epoll-level]: epoll策略中的`level-triggered`. 其实没有这个选项, 只是笔者为了区分`EPOLLET`特意标注的. 用来表示epoll的级别(`电平`)模式

[^ann-epoll-ctl-0]: 重新注册并不是说直接删除原来监听的文件描述符, 然后再添加. 当然这样也可以. 其实只需要`EPOLL_CTL_MOD`就可以了. 这所以这样做是因为, 若是以删除再重新添加, 则内核会做红黑树的删除和插入调整, 红黑树中若存在大量的结点,  这个调整就会影响到效率. 以MOD方式的话, 则内核直接快速定位到该结束, 直接修改


[^ann-epoll-wakeup]: 在特定条件下系统保持唤醒状态, 可以防止系统在特定事件到达时进入睡眠状态, 以便及时处理相关事件. 笔者这里不讨论这种场景.












